{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Neural Network on Gas Turbines Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modin.pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from keras.layers import Dense\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from keras import Sequential\n",
    "#import ray\n",
    "#ray.init(runtime_env={'env_vars': {'__MODIN_AUTOIMPORT_PANDAS__': '1'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gas=pd.read_csv(\"C:\\\\Users\\\\Hi\\\\Desktop\\\\Python Datasets\\\\gas_turbines.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#moving our Target  column to first column\n",
    "first_column=gas.pop('TEY')\n",
    "gas.insert(0,'TEY',first_column)\n",
    "gas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "gas.plot(kind='box',subplots=True, layout=(3,4),figsize=(20,20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zsc=stats.zscore(gas) #Trying to remove outliers based on Z scores and removing the datapoints which are above Zscore=3 \n",
    "zscores=np.abs(zsc)  #Making all values absolute to make -ve alues to +ve so that we can easily remove the Zscores above 3\n",
    "filter_zscores=(zscores<3).all(axis=1)\n",
    "filtered=gas[filter_zscores]\n",
    "filtered.shape #here there are 492 rows outliers as we can see after transforming df and trying to eliminate the zvalues above 3 and below -3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered.plot(kind='box',layout=(4,3),figsize=(20,20),subplots=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets Try Isolation Forest method for Outlier Detection \n",
    "from sklearn.ensemble import IsolationForest\n",
    "clf=IsolationForest(random_state=20,contamination=0.10) #based on domain knowledge the contamination value should be set\n",
    "clf.fit(filtered)\n",
    "filtered['anomaly']=clf.predict(filtered)\n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping  1455 records at contamination of 10% assumption\n",
    "filtered.drop(filtered[filtered['anomaly']==-1].index,inplace=True)\n",
    "filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Using PPS Score to identify correlation\n",
    "import ppscore as pps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered=filtered.drop(['anomaly'],axis=1)\n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Automatic EDA using Sweetviz\n",
    "import sweetviz as sv\n",
    "sweet_report=sv.analyze(filtered)\n",
    "sweet_report.show_html('EDA_of_Gas_Turbines.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(filtered.corr(),annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we have 3 Multicollinearity problem between Columns which are TAT vs GTEP at -0.83 , TAT vs CDP at -0.82, TIT vs CO at -0.74 \n",
    "## We are going to consider Multicollinearity problem when there is >0.7 correlation between Independent Features(Columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But MultiCollinearity is handled very well by Neural Networks as Neural Networks have Back propagation and non-linear activation functions which makes multicollinearity unimportant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=filtered.iloc[:,1:]\n",
    "Y=filtered.iloc[:,:1]\n",
    "Y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Model by using Hyperparameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=np.asarray(x_train)\n",
    "y_train=np.asarray(y_train)\n",
    "x_test=np.asarray(x_test)\n",
    "y_test=np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from keras.layers import Dropout, Dense\n",
    "from keras import Sequential\n",
    "activation=['tanh','relu','leakyrelu','elu','sigmoid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "\n",
    "    model=Sequential()\n",
    "    for i in range(hp.Int('num_Layers',2,20)):\n",
    "\n",
    "        model.add(Dense(units=hp.Int('units_'+str(i),min_value=8,max_value=132,step=8),activation=hp.Choice('activation'+str(i),values=['tanh','relu','sigmoid'])))\n",
    "        model.add(Dropout(hp.Choice('dropout'+str(i),values=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9])))\n",
    "        model.add(Dense(1,activation='linear'))\n",
    "        model.compile(optimizer=keras.optimizers.Adamax(hp.Choice('learning_rate',[0.1,0.01,0.001])),loss='mean_absolute_error',metrics=['mean_absolute_error'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner=RandomSearch(hypermodel=build_model,objective='val_mean_absolute_error',max_trials=5,executions_per_trial=3,directory='project',project_name='Gas_Turbines',overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(x_train,y_train,epochs=100,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train,y_train,epochs=100,initial_epoch=5,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.optimizers import Adamax\n",
    "from keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below code will take more time than 4hours needs  GPUs to run fast  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def create_model(learning_rate,dropout_rate,activation_function,init,neuron1,neuron2):\n",
    "    model=Sequential()\n",
    "    model.add(Dense(neuron1,kernel_initializer=init,activation=activation_function))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neuron2,input_dim=neuron1,kernel_initializer=init,activation=activation_function))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1,activation='linear'))\n",
    "\n",
    "    adamax= Adamax(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=adamax, loss='rmsprop',metrics=['mean_absolute_error'])\n",
    "    return model\n",
    "\n",
    "#Create Model\n",
    "model=KerasRegressor(build_fn=create_model,verbose=0)\n",
    "\n",
    "\n",
    "#Parameters for GridSearchCV \n",
    "batch_size=[10,20,40]\n",
    "epochs=[10,50,100]\n",
    "learning_rate=[0.1,0.01,0.001]\n",
    "dropout_rate=[0.0,0.1,0.2]\n",
    "activation_function=['softmax','relu','tanh','linear']\n",
    "init=['uniform','normal','zero']\n",
    "neuron1=[4,8,16]\n",
    "neuron2=[2,4,8]\n",
    "\n",
    "#Make a Dictionary of Params Grid \n",
    "params_grid=dict(batch_size=batch_size,epochs=epochs,learning_rate=learning_rate,dropout_rate=dropout_rate,\n",
    "                      activation_function=activation_function,init=init,neuron1=neuron1,neuron2=neuron2)\n",
    "                \n",
    "#Build and fit the Grid Search CV\n",
    "grid=GridSearchCV(estimator=model,param_grid=params_grid)\n",
    "grid_result=grid.fit(X,Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "978d9105b068cbc356370494e3cb52e52fa7590bb9da26e4b7328c8ae4e62003"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
