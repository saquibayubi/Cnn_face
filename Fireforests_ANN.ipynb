{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install modin[all]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hi\\AppData\\Local\\Temp\\ipykernel_8980\\2682436600.py:5: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import RandomSearch\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import  keras\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from keras import layers\n",
    "from keras.layers import Dense\n",
    "from keras import Sequential\n",
    "#import modin.pandas as pd #using modin module to 70x pd computational speed\n",
    "#import ray\n",
    "#ray.init(runtime_env={'env_vars': {'__MODIN_AUTOIMPORT_PANDAS__': '1'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fire=pd.read_csv(\"C:\\\\Users\\\\Hi\\\\Desktop\\\\Python Datasets\\\\forestfires.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oct</td>\n",
       "      <td>tue</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oct</td>\n",
       "      <td>sat</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mar</td>\n",
       "      <td>sun</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "      <td>6.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "      <td>54.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "      <td>11.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>aug</td>\n",
       "      <td>sat</td>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>nov</td>\n",
       "      <td>tue</td>\n",
       "      <td>79.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain  ...  monthjan  \\\n",
       "0     mar  fri  86.2   26.2   94.3   5.1   8.2  51   6.7   0.0  ...         0   \n",
       "1     oct  tue  90.6   35.4  669.1   6.7  18.0  33   0.9   0.0  ...         0   \n",
       "2     oct  sat  90.6   43.7  686.9   6.7  14.6  33   1.3   0.0  ...         0   \n",
       "3     mar  fri  91.7   33.3   77.5   9.0   8.3  97   4.0   0.2  ...         0   \n",
       "4     mar  sun  89.3   51.3  102.2   9.6  11.4  99   1.8   0.0  ...         0   \n",
       "..    ...  ...   ...    ...    ...   ...   ...  ..   ...   ...  ...       ...   \n",
       "512   aug  sun  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0  ...         0   \n",
       "513   aug  sun  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  ...         0   \n",
       "514   aug  sun  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  ...         0   \n",
       "515   aug  sat  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0  ...         0   \n",
       "516   nov  tue  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0  ...         0   \n",
       "\n",
       "     monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  monthsep  \\\n",
       "0           0         0         1         0         0         0         0   \n",
       "1           0         0         0         0         0         1         0   \n",
       "2           0         0         0         0         0         1         0   \n",
       "3           0         0         1         0         0         0         0   \n",
       "4           0         0         1         0         0         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         1         0         0   \n",
       "\n",
       "     size_category   area  \n",
       "0            small   0.00  \n",
       "1            small   0.00  \n",
       "2            small   0.00  \n",
       "3            small   0.00  \n",
       "4            small   0.00  \n",
       "..             ...    ...  \n",
       "512          large   6.44  \n",
       "513          large  54.29  \n",
       "514          large  11.16  \n",
       "515          small   0.00  \n",
       "516          small   0.00  \n",
       "\n",
       "[517 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>dayfri</th>\n",
       "      <th>daymon</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>90.644681</td>\n",
       "      <td>110.872340</td>\n",
       "      <td>547.940039</td>\n",
       "      <td>9.021663</td>\n",
       "      <td>18.889168</td>\n",
       "      <td>44.288201</td>\n",
       "      <td>4.017602</td>\n",
       "      <td>0.021663</td>\n",
       "      <td>0.164410</td>\n",
       "      <td>0.143133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038685</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.061896</td>\n",
       "      <td>0.032882</td>\n",
       "      <td>0.104449</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.001934</td>\n",
       "      <td>0.029014</td>\n",
       "      <td>0.332689</td>\n",
       "      <td>12.847292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.520111</td>\n",
       "      <td>64.046482</td>\n",
       "      <td>248.066192</td>\n",
       "      <td>4.559477</td>\n",
       "      <td>5.806625</td>\n",
       "      <td>16.317469</td>\n",
       "      <td>1.791653</td>\n",
       "      <td>0.295959</td>\n",
       "      <td>0.371006</td>\n",
       "      <td>0.350548</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193029</td>\n",
       "      <td>0.062137</td>\n",
       "      <td>0.241199</td>\n",
       "      <td>0.178500</td>\n",
       "      <td>0.306138</td>\n",
       "      <td>0.062137</td>\n",
       "      <td>0.043980</td>\n",
       "      <td>0.168007</td>\n",
       "      <td>0.471632</td>\n",
       "      <td>63.655818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.700000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>90.200000</td>\n",
       "      <td>68.600000</td>\n",
       "      <td>437.700000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>91.600000</td>\n",
       "      <td>108.300000</td>\n",
       "      <td>664.200000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>19.300000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>92.900000</td>\n",
       "      <td>142.400000</td>\n",
       "      <td>713.900000</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>22.800000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>96.200000</td>\n",
       "      <td>291.300000</td>\n",
       "      <td>860.600000</td>\n",
       "      <td>56.100000</td>\n",
       "      <td>33.300000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1090.840000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             FFMC         DMC          DC         ISI        temp          RH  \\\n",
       "count  517.000000  517.000000  517.000000  517.000000  517.000000  517.000000   \n",
       "mean    90.644681  110.872340  547.940039    9.021663   18.889168   44.288201   \n",
       "std      5.520111   64.046482  248.066192    4.559477    5.806625   16.317469   \n",
       "min     18.700000    1.100000    7.900000    0.000000    2.200000   15.000000   \n",
       "25%     90.200000   68.600000  437.700000    6.500000   15.500000   33.000000   \n",
       "50%     91.600000  108.300000  664.200000    8.400000   19.300000   42.000000   \n",
       "75%     92.900000  142.400000  713.900000   10.800000   22.800000   53.000000   \n",
       "max     96.200000  291.300000  860.600000   56.100000   33.300000  100.000000   \n",
       "\n",
       "             wind        rain      dayfri      daymon  ...    monthfeb  \\\n",
       "count  517.000000  517.000000  517.000000  517.000000  ...  517.000000   \n",
       "mean     4.017602    0.021663    0.164410    0.143133  ...    0.038685   \n",
       "std      1.791653    0.295959    0.371006    0.350548  ...    0.193029   \n",
       "min      0.400000    0.000000    0.000000    0.000000  ...    0.000000   \n",
       "25%      2.700000    0.000000    0.000000    0.000000  ...    0.000000   \n",
       "50%      4.000000    0.000000    0.000000    0.000000  ...    0.000000   \n",
       "75%      4.900000    0.000000    0.000000    0.000000  ...    0.000000   \n",
       "max      9.400000    6.400000    1.000000    1.000000  ...    1.000000   \n",
       "\n",
       "         monthjan    monthjul    monthjun    monthmar    monthmay    monthnov  \\\n",
       "count  517.000000  517.000000  517.000000  517.000000  517.000000  517.000000   \n",
       "mean     0.003868    0.061896    0.032882    0.104449    0.003868    0.001934   \n",
       "std      0.062137    0.241199    0.178500    0.306138    0.062137    0.043980   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         monthoct    monthsep         area  \n",
       "count  517.000000  517.000000   517.000000  \n",
       "mean     0.029014    0.332689    12.847292  \n",
       "std      0.168007    0.471632    63.655818  \n",
       "min      0.000000    0.000000     0.000000  \n",
       "25%      0.000000    0.000000     0.000000  \n",
       "50%      0.000000    0.000000     0.520000  \n",
       "75%      0.000000    1.000000     6.570000  \n",
       "max      1.000000    1.000000  1090.840000  \n",
       "\n",
       "[8 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 517 entries, 0 to 516\n",
      "Data columns (total 31 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   month          517 non-null    object \n",
      " 1   day            517 non-null    object \n",
      " 2   FFMC           517 non-null    float64\n",
      " 3   DMC            517 non-null    float64\n",
      " 4   DC             517 non-null    float64\n",
      " 5   ISI            517 non-null    float64\n",
      " 6   temp           517 non-null    float64\n",
      " 7   RH             517 non-null    int64  \n",
      " 8   wind           517 non-null    float64\n",
      " 9   rain           517 non-null    float64\n",
      " 10  dayfri         517 non-null    int64  \n",
      " 11  daymon         517 non-null    int64  \n",
      " 12  daysat         517 non-null    int64  \n",
      " 13  daysun         517 non-null    int64  \n",
      " 14  daythu         517 non-null    int64  \n",
      " 15  daytue         517 non-null    int64  \n",
      " 16  daywed         517 non-null    int64  \n",
      " 17  monthapr       517 non-null    int64  \n",
      " 18  monthaug       517 non-null    int64  \n",
      " 19  monthdec       517 non-null    int64  \n",
      " 20  monthfeb       517 non-null    int64  \n",
      " 21  monthjan       517 non-null    int64  \n",
      " 22  monthjul       517 non-null    int64  \n",
      " 23  monthjun       517 non-null    int64  \n",
      " 24  monthmar       517 non-null    int64  \n",
      " 25  monthmay       517 non-null    int64  \n",
      " 26  monthnov       517 non-null    int64  \n",
      " 27  monthoct       517 non-null    int64  \n",
      " 28  monthsep       517 non-null    int64  \n",
      " 29  size_category  517 non-null    object \n",
      " 30  area           517 non-null    float64\n",
      "dtypes: float64(8), int64(20), object(3)\n",
      "memory usage: 125.3+ KB\n"
     ]
    }
   ],
   "source": [
    "fire.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fire=fire.drop(['month','day'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>dayfri</th>\n",
       "      <th>daymon</th>\n",
       "      <th>...</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "      <td>6.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "      <td>54.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "      <td>11.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>79.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FFMC    DMC     DC   ISI  temp  RH  wind  rain  dayfri  daymon  ...  \\\n",
       "0    86.2   26.2   94.3   5.1   8.2  51   6.7   0.0       1       0  ...   \n",
       "1    90.6   35.4  669.1   6.7  18.0  33   0.9   0.0       0       0  ...   \n",
       "2    90.6   43.7  686.9   6.7  14.6  33   1.3   0.0       0       0  ...   \n",
       "3    91.7   33.3   77.5   9.0   8.3  97   4.0   0.2       1       0  ...   \n",
       "4    89.3   51.3  102.2   9.6  11.4  99   1.8   0.0       0       0  ...   \n",
       "..    ...    ...    ...   ...   ...  ..   ...   ...     ...     ...  ...   \n",
       "512  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0       0       0  ...   \n",
       "513  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0       0       0  ...   \n",
       "514  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0       0       0  ...   \n",
       "515  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0       0       0  ...   \n",
       "516  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0       0       0  ...   \n",
       "\n",
       "     monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0           0         0         0         1         0         0         0   \n",
       "1           0         0         0         0         0         0         1   \n",
       "2           0         0         0         0         0         0         1   \n",
       "3           0         0         0         1         0         0         0   \n",
       "4           0         0         0         1         0         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         1         0   \n",
       "\n",
       "     monthsep  size_category   area  \n",
       "0           0          small   0.00  \n",
       "1           0          small   0.00  \n",
       "2           0          small   0.00  \n",
       "3           0          small   0.00  \n",
       "4           0          small   0.00  \n",
       "..        ...            ...    ...  \n",
       "512         0          large   6.44  \n",
       "513         0          large  54.29  \n",
       "514         0          large  11.16  \n",
       "515         0          small   0.00  \n",
       "516         0          small   0.00  \n",
       "\n",
       "[517 rows x 29 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x2000 with 50 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fire.plot(kind='box',subplots=True, layout=(10,5),figsize=(20,20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>dayfri</th>\n",
       "      <th>daymon</th>\n",
       "      <th>...</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>79.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FFMC    DMC     DC   ISI  temp  RH  wind  rain  dayfri  daymon  ...  \\\n",
       "0    86.2   26.2   94.3   5.1   8.2  51   6.7   0.0       1       0  ...   \n",
       "1    90.6   35.4  669.1   6.7  18.0  33   0.9   0.0       0       0  ...   \n",
       "2    90.6   43.7  686.9   6.7  14.6  33   1.3   0.0       0       0  ...   \n",
       "3    91.7   33.3   77.5   9.0   8.3  97   4.0   0.2       1       0  ...   \n",
       "4    89.3   51.3  102.2   9.6  11.4  99   1.8   0.0       0       0  ...   \n",
       "..    ...    ...    ...   ...   ...  ..   ...   ...     ...     ...  ...   \n",
       "512  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0       0       0  ...   \n",
       "513  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0       0       0  ...   \n",
       "514  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0       0       0  ...   \n",
       "515  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0       0       0  ...   \n",
       "516  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0       0       0  ...   \n",
       "\n",
       "     monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0           0         0         0         1         0         0         0   \n",
       "1           0         0         0         0         0         0         1   \n",
       "2           0         0         0         0         0         0         1   \n",
       "3           0         0         0         1         0         0         0   \n",
       "4           0         0         0         1         0         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         1         0   \n",
       "\n",
       "     monthsep  size_category   area  \n",
       "0           0              1   0.00  \n",
       "1           0              1   0.00  \n",
       "2           0              1   0.00  \n",
       "3           0              1   0.00  \n",
       "4           0              1   0.00  \n",
       "..        ...            ...    ...  \n",
       "512         0              0   6.44  \n",
       "513         0              0  54.29  \n",
       "514         0              0  11.16  \n",
       "515         0              1   0.00  \n",
       "516         0              1   0.00  \n",
       "\n",
       "[517 rows x 29 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le=LabelEncoder()\n",
    "fire['size_category']=le.fit_transform(fire['size_category'])\n",
    "fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>dayfri</th>\n",
       "      <th>daymon</th>\n",
       "      <th>...</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.805959</td>\n",
       "      <td>-1.323326</td>\n",
       "      <td>-1.830477</td>\n",
       "      <td>-0.860946</td>\n",
       "      <td>-1.842640</td>\n",
       "      <td>0.411724</td>\n",
       "      <td>1.498614</td>\n",
       "      <td>-0.073268</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.008102</td>\n",
       "      <td>-1.179541</td>\n",
       "      <td>0.488891</td>\n",
       "      <td>-0.509688</td>\n",
       "      <td>-0.153278</td>\n",
       "      <td>-0.692456</td>\n",
       "      <td>-1.741756</td>\n",
       "      <td>-0.073268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.008102</td>\n",
       "      <td>-1.049822</td>\n",
       "      <td>0.560715</td>\n",
       "      <td>-0.509688</td>\n",
       "      <td>-0.739383</td>\n",
       "      <td>-0.692456</td>\n",
       "      <td>-1.518282</td>\n",
       "      <td>-0.073268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.191362</td>\n",
       "      <td>-1.212361</td>\n",
       "      <td>-1.898266</td>\n",
       "      <td>-0.004756</td>\n",
       "      <td>-1.825402</td>\n",
       "      <td>3.233519</td>\n",
       "      <td>-0.009834</td>\n",
       "      <td>0.603155</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.243833</td>\n",
       "      <td>-0.931043</td>\n",
       "      <td>-1.798600</td>\n",
       "      <td>0.126966</td>\n",
       "      <td>-1.291012</td>\n",
       "      <td>3.356206</td>\n",
       "      <td>-1.238940</td>\n",
       "      <td>-0.073268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>-1.640083</td>\n",
       "      <td>-0.846648</td>\n",
       "      <td>0.474768</td>\n",
       "      <td>-1.563460</td>\n",
       "      <td>1.536084</td>\n",
       "      <td>-0.753800</td>\n",
       "      <td>-0.736124</td>\n",
       "      <td>-0.073268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>-1.640083</td>\n",
       "      <td>-0.846648</td>\n",
       "      <td>0.474768</td>\n",
       "      <td>-1.563460</td>\n",
       "      <td>0.519019</td>\n",
       "      <td>1.638592</td>\n",
       "      <td>0.995798</td>\n",
       "      <td>-0.073268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>-1.640083</td>\n",
       "      <td>-0.846648</td>\n",
       "      <td>0.474768</td>\n",
       "      <td>-1.563460</td>\n",
       "      <td>0.398350</td>\n",
       "      <td>1.577248</td>\n",
       "      <td>1.498614</td>\n",
       "      <td>-0.073268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>0.680957</td>\n",
       "      <td>0.549003</td>\n",
       "      <td>0.269382</td>\n",
       "      <td>0.500176</td>\n",
       "      <td>1.156839</td>\n",
       "      <td>-0.140366</td>\n",
       "      <td>-0.009834</td>\n",
       "      <td>-0.073268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>-2.020879</td>\n",
       "      <td>-1.685913</td>\n",
       "      <td>-1.780442</td>\n",
       "      <td>-1.739089</td>\n",
       "      <td>-1.222058</td>\n",
       "      <td>-0.815143</td>\n",
       "      <td>0.269509</td>\n",
       "      <td>-0.073268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         FFMC       DMC        DC       ISI      temp        RH      wind  \\\n",
       "0   -0.805959 -1.323326 -1.830477 -0.860946 -1.842640  0.411724  1.498614   \n",
       "1   -0.008102 -1.179541  0.488891 -0.509688 -0.153278 -0.692456 -1.741756   \n",
       "2   -0.008102 -1.049822  0.560715 -0.509688 -0.739383 -0.692456 -1.518282   \n",
       "3    0.191362 -1.212361 -1.898266 -0.004756 -1.825402  3.233519 -0.009834   \n",
       "4   -0.243833 -0.931043 -1.798600  0.126966 -1.291012  3.356206 -1.238940   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512 -1.640083 -0.846648  0.474768 -1.563460  1.536084 -0.753800 -0.736124   \n",
       "513 -1.640083 -0.846648  0.474768 -1.563460  0.519019  1.638592  0.995798   \n",
       "514 -1.640083 -0.846648  0.474768 -1.563460  0.398350  1.577248  1.498614   \n",
       "515  0.680957  0.549003  0.269382  0.500176  1.156839 -0.140366 -0.009834   \n",
       "516 -2.020879 -1.685913 -1.780442 -1.739089 -1.222058 -0.815143  0.269509   \n",
       "\n",
       "         rain  dayfri  daymon  ...  monthjan  monthjul  monthjun  monthmar  \\\n",
       "0   -0.073268       1       0  ...         0         0         0         1   \n",
       "1   -0.073268       0       0  ...         0         0         0         0   \n",
       "2   -0.073268       0       0  ...         0         0         0         0   \n",
       "3    0.603155       1       0  ...         0         0         0         1   \n",
       "4   -0.073268       0       0  ...         0         0         0         1   \n",
       "..        ...     ...     ...  ...       ...       ...       ...       ...   \n",
       "512 -0.073268       0       0  ...         0         0         0         0   \n",
       "513 -0.073268       0       0  ...         0         0         0         0   \n",
       "514 -0.073268       0       0  ...         0         0         0         0   \n",
       "515 -0.073268       0       0  ...         0         0         0         0   \n",
       "516 -0.073268       0       0  ...         0         0         0         0   \n",
       "\n",
       "     monthmay  monthnov  monthoct  monthsep  size_category   area  \n",
       "0           0         0         0         0              1   0.00  \n",
       "1           0         0         1         0              1   0.00  \n",
       "2           0         0         1         0              1   0.00  \n",
       "3           0         0         0         0              1   0.00  \n",
       "4           0         0         0         0              1   0.00  \n",
       "..        ...       ...       ...       ...            ...    ...  \n",
       "512         0         0         0         0              0   6.44  \n",
       "513         0         0         0         0              0  54.29  \n",
       "514         0         0         0         0              0  11.16  \n",
       "515         0         0         0         0              1   0.00  \n",
       "516         0         1         0         0              1   0.00  \n",
       "\n",
       "[517 rows x 29 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler=StandardScaler()\n",
    "fire[['FFMC','DMC','DC','ISI','temp','RH','wind','rain']]=scaler.fit_transform(fire[['FFMC','DMC','DC','ISI','temp','RH','wind','rain']])\n",
    "fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "zsc=stats.zscore(fire)\n",
    "zscores=np.abs(zsc)\n",
    "filter_zscores=(zscores<3).all(axis=1)\n",
    "filtered=fire[filter_zscores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(395, 29)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517, 29)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>dayfri</th>\n",
       "      <th>daymon</th>\n",
       "      <th>...</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.805959</td>\n",
       "      <td>-1.323326</td>\n",
       "      <td>-1.830477</td>\n",
       "      <td>-0.860946</td>\n",
       "      <td>-1.842640</td>\n",
       "      <td>0.411724</td>\n",
       "      <td>1.498614</td>\n",
       "      <td>-0.073268</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.300161</td>\n",
       "      <td>-0.399665</td>\n",
       "      <td>-0.241863</td>\n",
       "      <td>1.246598</td>\n",
       "      <td>0.570734</td>\n",
       "      <td>-0.937830</td>\n",
       "      <td>0.772325</td>\n",
       "      <td>-0.073268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.300161</td>\n",
       "      <td>-0.343401</td>\n",
       "      <td>-0.211197</td>\n",
       "      <td>-0.114524</td>\n",
       "      <td>0.898263</td>\n",
       "      <td>-1.060516</td>\n",
       "      <td>-0.512650</td>\n",
       "      <td>-0.073268</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.155096</td>\n",
       "      <td>0.539625</td>\n",
       "      <td>0.243154</td>\n",
       "      <td>0.368455</td>\n",
       "      <td>-1.877117</td>\n",
       "      <td>2.558742</td>\n",
       "      <td>-1.015466</td>\n",
       "      <td>-0.073268</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.064430</td>\n",
       "      <td>0.291128</td>\n",
       "      <td>0.583715</td>\n",
       "      <td>-0.443828</td>\n",
       "      <td>-0.997959</td>\n",
       "      <td>1.147845</td>\n",
       "      <td>0.772325</td>\n",
       "      <td>-0.073268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>-1.640083</td>\n",
       "      <td>-0.846648</td>\n",
       "      <td>0.474768</td>\n",
       "      <td>-1.563460</td>\n",
       "      <td>1.536084</td>\n",
       "      <td>-0.569770</td>\n",
       "      <td>-0.736124</td>\n",
       "      <td>-0.073268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>-1.640083</td>\n",
       "      <td>-0.846648</td>\n",
       "      <td>0.474768</td>\n",
       "      <td>-1.563460</td>\n",
       "      <td>1.536084</td>\n",
       "      <td>-0.753800</td>\n",
       "      <td>-0.736124</td>\n",
       "      <td>-0.073268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>-1.640083</td>\n",
       "      <td>-0.846648</td>\n",
       "      <td>0.474768</td>\n",
       "      <td>-1.563460</td>\n",
       "      <td>0.519019</td>\n",
       "      <td>1.638592</td>\n",
       "      <td>0.995798</td>\n",
       "      <td>-0.073268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>-1.640083</td>\n",
       "      <td>-0.846648</td>\n",
       "      <td>0.474768</td>\n",
       "      <td>-1.563460</td>\n",
       "      <td>0.398350</td>\n",
       "      <td>1.577248</td>\n",
       "      <td>1.498614</td>\n",
       "      <td>-0.073268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>0.680957</td>\n",
       "      <td>0.549003</td>\n",
       "      <td>0.269382</td>\n",
       "      <td>0.500176</td>\n",
       "      <td>1.156839</td>\n",
       "      <td>-0.140366</td>\n",
       "      <td>-0.009834</td>\n",
       "      <td>-0.073268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>395 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         FFMC       DMC        DC       ISI      temp        RH      wind  \\\n",
       "0   -0.805959 -1.323326 -1.830477 -0.860946 -1.842640  0.411724  1.498614   \n",
       "5    0.300161 -0.399665 -0.241863  1.246598  0.570734 -0.937830  0.772325   \n",
       "6    0.300161 -0.343401 -0.211197 -0.114524  0.898263 -1.060516 -0.512650   \n",
       "7    0.155096  0.539625  0.243154  0.368455 -1.877117  2.558742 -1.015466   \n",
       "8    0.064430  0.291128  0.583715 -0.443828 -0.997959  1.147845  0.772325   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "511 -1.640083 -0.846648  0.474768 -1.563460  1.536084 -0.569770 -0.736124   \n",
       "512 -1.640083 -0.846648  0.474768 -1.563460  1.536084 -0.753800 -0.736124   \n",
       "513 -1.640083 -0.846648  0.474768 -1.563460  0.519019  1.638592  0.995798   \n",
       "514 -1.640083 -0.846648  0.474768 -1.563460  0.398350  1.577248  1.498614   \n",
       "515  0.680957  0.549003  0.269382  0.500176  1.156839 -0.140366 -0.009834   \n",
       "\n",
       "         rain  dayfri  daymon  ...  monthjan  monthjul  monthjun  monthmar  \\\n",
       "0   -0.073268       1       0  ...         0         0         0         1   \n",
       "5   -0.073268       0       0  ...         0         0         0         0   \n",
       "6   -0.073268       0       1  ...         0         0         0         0   \n",
       "7   -0.073268       0       1  ...         0         0         0         0   \n",
       "8   -0.073268       0       0  ...         0         0         0         0   \n",
       "..        ...     ...     ...  ...       ...       ...       ...       ...   \n",
       "511 -0.073268       0       0  ...         0         0         0         0   \n",
       "512 -0.073268       0       0  ...         0         0         0         0   \n",
       "513 -0.073268       0       0  ...         0         0         0         0   \n",
       "514 -0.073268       0       0  ...         0         0         0         0   \n",
       "515 -0.073268       0       0  ...         0         0         0         0   \n",
       "\n",
       "     monthmay  monthnov  monthoct  monthsep  size_category   area  \n",
       "0           0         0         0         0              1   0.00  \n",
       "5           0         0         0         0              1   0.00  \n",
       "6           0         0         0         0              1   0.00  \n",
       "7           0         0         0         0              1   0.00  \n",
       "8           0         0         0         1              1   0.00  \n",
       "..        ...       ...       ...       ...            ...    ...  \n",
       "511         0         0         0         0              1   0.00  \n",
       "512         0         0         0         0              0   6.44  \n",
       "513         0         0         0         0              0  54.29  \n",
       "514         0         0         0         0              0  11.16  \n",
       "515         0         0         0         0              1   0.00  \n",
       "\n",
       "[395 rows x 29 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x2000 with 50 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filtered.plot(kind='box',subplots=True, layout=(10,5),figsize=(20,20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hi\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IsolationForest(contamination=0.05, random_state=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "clf=IsolationForest(contamination=0.05,random_state=0)\n",
    "clf.fit(filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hi\\AppData\\Local\\Temp\\ipykernel_8980\\2527682585.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered['anomaly']=clf.predict(filtered)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>dayfri</th>\n",
       "      <th>daymon</th>\n",
       "      <th>...</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "      <th>area</th>\n",
       "      <th>anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.805959</td>\n",
       "      <td>-1.323326</td>\n",
       "      <td>-1.830477</td>\n",
       "      <td>-0.860946</td>\n",
       "      <td>-1.842640</td>\n",
       "      <td>0.411724</td>\n",
       "      <td>1.498614</td>\n",
       "      <td>-0.073268</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.300161</td>\n",
       "      <td>-0.399665</td>\n",
       "      <td>-0.241863</td>\n",
       "      <td>1.246598</td>\n",
       "      <td>0.570734</td>\n",
       "      <td>-0.937830</td>\n",
       "      <td>0.772325</td>\n",
       "      <td>-0.073268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.300161</td>\n",
       "      <td>-0.343401</td>\n",
       "      <td>-0.211197</td>\n",
       "      <td>-0.114524</td>\n",
       "      <td>0.898263</td>\n",
       "      <td>-1.060516</td>\n",
       "      <td>-0.512650</td>\n",
       "      <td>-0.073268</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.155096</td>\n",
       "      <td>0.539625</td>\n",
       "      <td>0.243154</td>\n",
       "      <td>0.368455</td>\n",
       "      <td>-1.877117</td>\n",
       "      <td>2.558742</td>\n",
       "      <td>-1.015466</td>\n",
       "      <td>-0.073268</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.064430</td>\n",
       "      <td>0.291128</td>\n",
       "      <td>0.583715</td>\n",
       "      <td>-0.443828</td>\n",
       "      <td>-0.997959</td>\n",
       "      <td>1.147845</td>\n",
       "      <td>0.772325</td>\n",
       "      <td>-0.073268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>-1.640083</td>\n",
       "      <td>-0.846648</td>\n",
       "      <td>0.474768</td>\n",
       "      <td>-1.563460</td>\n",
       "      <td>1.536084</td>\n",
       "      <td>-0.569770</td>\n",
       "      <td>-0.736124</td>\n",
       "      <td>-0.073268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>-1.640083</td>\n",
       "      <td>-0.846648</td>\n",
       "      <td>0.474768</td>\n",
       "      <td>-1.563460</td>\n",
       "      <td>1.536084</td>\n",
       "      <td>-0.753800</td>\n",
       "      <td>-0.736124</td>\n",
       "      <td>-0.073268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.44</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>-1.640083</td>\n",
       "      <td>-0.846648</td>\n",
       "      <td>0.474768</td>\n",
       "      <td>-1.563460</td>\n",
       "      <td>0.519019</td>\n",
       "      <td>1.638592</td>\n",
       "      <td>0.995798</td>\n",
       "      <td>-0.073268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.29</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>-1.640083</td>\n",
       "      <td>-0.846648</td>\n",
       "      <td>0.474768</td>\n",
       "      <td>-1.563460</td>\n",
       "      <td>0.398350</td>\n",
       "      <td>1.577248</td>\n",
       "      <td>1.498614</td>\n",
       "      <td>-0.073268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.16</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>0.680957</td>\n",
       "      <td>0.549003</td>\n",
       "      <td>0.269382</td>\n",
       "      <td>0.500176</td>\n",
       "      <td>1.156839</td>\n",
       "      <td>-0.140366</td>\n",
       "      <td>-0.009834</td>\n",
       "      <td>-0.073268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>395 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         FFMC       DMC        DC       ISI      temp        RH      wind  \\\n",
       "0   -0.805959 -1.323326 -1.830477 -0.860946 -1.842640  0.411724  1.498614   \n",
       "5    0.300161 -0.399665 -0.241863  1.246598  0.570734 -0.937830  0.772325   \n",
       "6    0.300161 -0.343401 -0.211197 -0.114524  0.898263 -1.060516 -0.512650   \n",
       "7    0.155096  0.539625  0.243154  0.368455 -1.877117  2.558742 -1.015466   \n",
       "8    0.064430  0.291128  0.583715 -0.443828 -0.997959  1.147845  0.772325   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "511 -1.640083 -0.846648  0.474768 -1.563460  1.536084 -0.569770 -0.736124   \n",
       "512 -1.640083 -0.846648  0.474768 -1.563460  1.536084 -0.753800 -0.736124   \n",
       "513 -1.640083 -0.846648  0.474768 -1.563460  0.519019  1.638592  0.995798   \n",
       "514 -1.640083 -0.846648  0.474768 -1.563460  0.398350  1.577248  1.498614   \n",
       "515  0.680957  0.549003  0.269382  0.500176  1.156839 -0.140366 -0.009834   \n",
       "\n",
       "         rain  dayfri  daymon  ...  monthjul  monthjun  monthmar  monthmay  \\\n",
       "0   -0.073268       1       0  ...         0         0         1         0   \n",
       "5   -0.073268       0       0  ...         0         0         0         0   \n",
       "6   -0.073268       0       1  ...         0         0         0         0   \n",
       "7   -0.073268       0       1  ...         0         0         0         0   \n",
       "8   -0.073268       0       0  ...         0         0         0         0   \n",
       "..        ...     ...     ...  ...       ...       ...       ...       ...   \n",
       "511 -0.073268       0       0  ...         0         0         0         0   \n",
       "512 -0.073268       0       0  ...         0         0         0         0   \n",
       "513 -0.073268       0       0  ...         0         0         0         0   \n",
       "514 -0.073268       0       0  ...         0         0         0         0   \n",
       "515 -0.073268       0       0  ...         0         0         0         0   \n",
       "\n",
       "     monthnov  monthoct  monthsep  size_category   area  anomaly  \n",
       "0           0         0         0              1   0.00        1  \n",
       "5           0         0         0              1   0.00        1  \n",
       "6           0         0         0              1   0.00        1  \n",
       "7           0         0         0              1   0.00        1  \n",
       "8           0         0         1              1   0.00        1  \n",
       "..        ...       ...       ...            ...    ...      ...  \n",
       "511         0         0         0              1   0.00        1  \n",
       "512         0         0         0              0   6.44       -1  \n",
       "513         0         0         0              0  54.29       -1  \n",
       "514         0         0         0              0  11.16       -1  \n",
       "515         0         0         0              1   0.00        1  \n",
       "\n",
       "[395 rows x 30 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered['anomaly']=clf.predict(filtered)\n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(395, 30)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hi\\AppData\\Local\\Temp\\ipykernel_8980\\532726151.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered.drop(filtered[filtered['anomaly']==-1].index,inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(375, 30)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# through Isolation forest we have dropped 20 records at assumption of 5% contamination\n",
    "filtered.drop(filtered[filtered['anomaly']==-1].index,inplace=True)\n",
    "filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>dayfri</th>\n",
       "      <th>daymon</th>\n",
       "      <th>...</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.805959</td>\n",
       "      <td>-1.323326</td>\n",
       "      <td>-1.830477</td>\n",
       "      <td>-0.860946</td>\n",
       "      <td>-1.842640</td>\n",
       "      <td>0.411724</td>\n",
       "      <td>1.498614</td>\n",
       "      <td>-0.073268</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.300161</td>\n",
       "      <td>-0.399665</td>\n",
       "      <td>-0.241863</td>\n",
       "      <td>1.246598</td>\n",
       "      <td>0.570734</td>\n",
       "      <td>-0.937830</td>\n",
       "      <td>0.772325</td>\n",
       "      <td>-0.073268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.300161</td>\n",
       "      <td>-0.343401</td>\n",
       "      <td>-0.211197</td>\n",
       "      <td>-0.114524</td>\n",
       "      <td>0.898263</td>\n",
       "      <td>-1.060516</td>\n",
       "      <td>-0.512650</td>\n",
       "      <td>-0.073268</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.155096</td>\n",
       "      <td>0.539625</td>\n",
       "      <td>0.243154</td>\n",
       "      <td>0.368455</td>\n",
       "      <td>-1.877117</td>\n",
       "      <td>2.558742</td>\n",
       "      <td>-1.015466</td>\n",
       "      <td>-0.073268</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.064430</td>\n",
       "      <td>0.291128</td>\n",
       "      <td>0.583715</td>\n",
       "      <td>-0.443828</td>\n",
       "      <td>-0.997959</td>\n",
       "      <td>1.147845</td>\n",
       "      <td>0.772325</td>\n",
       "      <td>-0.073268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>0.064430</td>\n",
       "      <td>0.875644</td>\n",
       "      <td>0.825821</td>\n",
       "      <td>-0.421874</td>\n",
       "      <td>1.208554</td>\n",
       "      <td>-0.201709</td>\n",
       "      <td>-0.233308</td>\n",
       "      <td>-0.073268</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>0.064430</td>\n",
       "      <td>0.875644</td>\n",
       "      <td>0.825821</td>\n",
       "      <td>-0.421874</td>\n",
       "      <td>1.208554</td>\n",
       "      <td>-0.201709</td>\n",
       "      <td>-0.233308</td>\n",
       "      <td>-0.073268</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>0.064430</td>\n",
       "      <td>0.875644</td>\n",
       "      <td>0.825821</td>\n",
       "      <td>-0.421874</td>\n",
       "      <td>-0.118801</td>\n",
       "      <td>1.086501</td>\n",
       "      <td>0.772325</td>\n",
       "      <td>-0.073268</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>-1.640083</td>\n",
       "      <td>-0.846648</td>\n",
       "      <td>0.474768</td>\n",
       "      <td>-1.563460</td>\n",
       "      <td>1.536084</td>\n",
       "      <td>-0.569770</td>\n",
       "      <td>-0.736124</td>\n",
       "      <td>-0.073268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>0.680957</td>\n",
       "      <td>0.549003</td>\n",
       "      <td>0.269382</td>\n",
       "      <td>0.500176</td>\n",
       "      <td>1.156839</td>\n",
       "      <td>-0.140366</td>\n",
       "      <td>-0.009834</td>\n",
       "      <td>-0.073268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>375 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         FFMC       DMC        DC       ISI      temp        RH      wind  \\\n",
       "0   -0.805959 -1.323326 -1.830477 -0.860946 -1.842640  0.411724  1.498614   \n",
       "5    0.300161 -0.399665 -0.241863  1.246598  0.570734 -0.937830  0.772325   \n",
       "6    0.300161 -0.343401 -0.211197 -0.114524  0.898263 -1.060516 -0.512650   \n",
       "7    0.155096  0.539625  0.243154  0.368455 -1.877117  2.558742 -1.015466   \n",
       "8    0.064430  0.291128  0.583715 -0.443828 -0.997959  1.147845  0.772325   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "507  0.064430  0.875644  0.825821 -0.421874  1.208554 -0.201709 -0.233308   \n",
       "508  0.064430  0.875644  0.825821 -0.421874  1.208554 -0.201709 -0.233308   \n",
       "510  0.064430  0.875644  0.825821 -0.421874 -0.118801  1.086501  0.772325   \n",
       "511 -1.640083 -0.846648  0.474768 -1.563460  1.536084 -0.569770 -0.736124   \n",
       "515  0.680957  0.549003  0.269382  0.500176  1.156839 -0.140366 -0.009834   \n",
       "\n",
       "         rain  dayfri  daymon  ...  monthjan  monthjul  monthjun  monthmar  \\\n",
       "0   -0.073268       1       0  ...         0         0         0         1   \n",
       "5   -0.073268       0       0  ...         0         0         0         0   \n",
       "6   -0.073268       0       1  ...         0         0         0         0   \n",
       "7   -0.073268       0       1  ...         0         0         0         0   \n",
       "8   -0.073268       0       0  ...         0         0         0         0   \n",
       "..        ...     ...     ...  ...       ...       ...       ...       ...   \n",
       "507 -0.073268       1       0  ...         0         0         0         0   \n",
       "508 -0.073268       1       0  ...         0         0         0         0   \n",
       "510 -0.073268       1       0  ...         0         0         0         0   \n",
       "511 -0.073268       0       0  ...         0         0         0         0   \n",
       "515 -0.073268       0       0  ...         0         0         0         0   \n",
       "\n",
       "     monthmay  monthnov  monthoct  monthsep  size_category  area  \n",
       "0           0         0         0         0              1  0.00  \n",
       "5           0         0         0         0              1  0.00  \n",
       "6           0         0         0         0              1  0.00  \n",
       "7           0         0         0         0              1  0.00  \n",
       "8           0         0         0         1              1  0.00  \n",
       "..        ...       ...       ...       ...            ...   ...  \n",
       "507         0         0         0         0              1  0.00  \n",
       "508         0         0         0         0              1  0.00  \n",
       "510         0         0         0         0              1  0.43  \n",
       "511         0         0         0         0              1  0.00  \n",
       "515         0         0         0         0              1  0.00  \n",
       "\n",
       "[375 rows x 29 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered=filtered.drop(['anomaly'],axis=1)\n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>375 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     area\n",
       "0    0.00\n",
       "5    0.00\n",
       "6    0.00\n",
       "7    0.00\n",
       "8    0.00\n",
       "..    ...\n",
       "507  0.00\n",
       "508  0.00\n",
       "510  0.43\n",
       "511  0.00\n",
       "515  0.00\n",
       "\n",
       "[375 rows x 1 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=filtered.iloc[:,:28]\n",
    "Y=filtered.iloc[:,28:]\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.33,random_state=0)\n",
    "#converting train test variable to array in order to use modin,pandas to improve computational speed by 70x\n",
    "x_train=np.asarray(x_train)\n",
    "y_train=np.asarray(y_train)\n",
    "x_test=np.asarray(x_test)\n",
    "y_test=np.asarray(y_test)\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hi\\AppData\\Local\\Temp\\ipykernel_8980\\4266945810.py:14: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model =KerasRegressor(build_fn=create_model,verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8748 candidates, totalling 43740 fits\n",
      "[CV 1/5; 1/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 1/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.3s\n",
      "[CV 2/5; 1/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 1/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 1/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 1/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 4/5; 1/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 1/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 1/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 1/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 2/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 2/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 2/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 2/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 3/5; 2/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 2/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 2/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 2/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 2/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 2/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 3/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 1/5; 3/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 3/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 2/5; 3/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 3/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 3/5; 3/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 3/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 4/5; 3/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 3/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 5/5; 3/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 4/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 4/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 4/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 4/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 4/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 4/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 4/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 4/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 4/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 4/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 5/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 5/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 5/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 5/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 5/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 5/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 5/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 5/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 5/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 5/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 6/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 1/5; 6/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 6/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 2/5; 6/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 6/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 3/5; 6/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 6/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 4/5; 6/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 5/5; 6/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 5/5; 6/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 7/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 1/5; 7/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 7/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 2/5; 7/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 7/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 3/5; 7/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 7/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 4/5; 7/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 7/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 5/5; 7/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 8/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 1/5; 8/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 8/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 2/5; 8/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 3/5; 8/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 3/5; 8/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 4/5; 8/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 4/5; 8/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 5/5; 8/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 5/5; 8/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 9/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 1/5; 9/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 9/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 2/5; 9/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 3/5; 9/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 3/5; 9/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 9/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 4/5; 9/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.2s\n",
      "[CV 5/5; 9/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 5/5; 9/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 1/5; 10/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 10/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 2/5; 10/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 10/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.3s\n",
      "[CV 3/5; 10/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 10/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.2s\n",
      "[CV 4/5; 10/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 10/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 5/5; 10/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 10/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 11/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 11/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 11/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 11/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 3/5; 11/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 11/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.2s\n",
      "[CV 4/5; 11/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 11/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.2s\n",
      "[CV 5/5; 11/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 11/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.2s\n",
      "[CV 1/5; 12/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 1/5; 12/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 2/5; 12/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 2/5; 12/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 3/5; 12/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 3/5; 12/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 4/5; 12/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 4/5; 12/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 5/5; 12/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 5/5; 12/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 13/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 13/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 13/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 13/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 13/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 13/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 13/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 13/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 13/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 13/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 14/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 14/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 14/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 14/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 14/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 14/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 14/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 14/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 14/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 14/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 15/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 1/5; 15/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 15/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 2/5; 15/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 15/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 3/5; 15/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 15/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 4/5; 15/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 15/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 5/5; 15/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 16/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 1/5; 16/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 16/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 2/5; 16/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 16/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 3/5; 16/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 16/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 4/5; 16/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 16/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 5/5; 16/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 17/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 1/5; 17/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 17/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 2/5; 17/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 17/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 3/5; 17/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 17/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 4/5; 17/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 17/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 5/5; 17/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 18/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 1/5; 18/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 18/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 2/5; 18/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 18/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 3/5; 18/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 18/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 4/5; 18/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 18/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 5/5; 18/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 19/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 19/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 19/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 19/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 19/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 19/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 19/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 19/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 19/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 19/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 20/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 20/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 20/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 20/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 20/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 20/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 20/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 20/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 20/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 20/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 21/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 1/5; 21/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 21/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 2/5; 21/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 21/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 3/5; 21/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 21/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 4/5; 21/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 21/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 5/5; 21/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 22/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 22/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 22/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 22/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 22/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 22/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 22/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 22/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 22/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 22/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 23/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 23/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 23/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 23/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 23/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 23/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 23/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 23/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 23/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 23/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 24/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 1/5; 24/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 24/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 2/5; 24/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 24/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 3/5; 24/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 24/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 4/5; 24/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 24/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 5/5; 24/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 25/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 1/5; 25/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 25/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 2/5; 25/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 25/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 3/5; 25/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 25/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 4/5; 25/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 25/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 5/5; 25/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 26/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 1/5; 26/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 26/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 2/5; 26/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 26/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 3/5; 26/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 26/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 4/5; 26/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 26/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 5/5; 26/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 27/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 1/5; 27/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 27/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 2/5; 27/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 27/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 3/5; 27/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 27/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 4/5; 27/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 27/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 5/5; 27/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 28/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 28/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 28/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 28/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 3/5; 28/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 28/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 28/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 28/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 28/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 28/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 29/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 29/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 29/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 29/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 29/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 29/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 29/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 29/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 29/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 29/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 30/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 1/5; 30/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 30/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 2/5; 30/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 30/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 3/5; 30/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 30/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 4/5; 30/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 30/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 5/5; 30/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 31/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 31/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 31/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 31/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 31/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 31/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 31/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 31/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 31/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 31/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 32/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 32/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 32/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 32/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 32/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 32/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 32/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 32/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 32/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 32/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 33/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 1/5; 33/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 33/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 2/5; 33/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 33/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 3/5; 33/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 33/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 4/5; 33/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 33/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 5/5; 33/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.3s\n",
      "[CV 1/5; 34/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 1/5; 34/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 34/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 2/5; 34/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 34/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 3/5; 34/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 34/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 4/5; 34/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 34/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 5/5; 34/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 35/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 1/5; 35/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 35/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 2/5; 35/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 35/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 3/5; 35/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 35/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 4/5; 35/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 35/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 5/5; 35/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 36/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 1/5; 36/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 36/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 2/5; 36/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 36/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 3/5; 36/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 36/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 4/5; 36/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 36/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 5/5; 36/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 37/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 37/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 37/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 37/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 37/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 37/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 37/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 37/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 37/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 37/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 38/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 38/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 38/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 38/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 38/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 38/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 38/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 38/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 38/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 38/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 39/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 1/5; 39/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 39/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 2/5; 39/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 39/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 3/5; 39/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 39/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 4/5; 39/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 39/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 5/5; 39/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 40/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 40/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 40/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 40/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 40/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 40/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 40/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 40/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 40/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 40/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 41/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 41/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 41/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 41/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 41/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 41/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 4/5; 41/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 41/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 41/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 41/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 42/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 1/5; 42/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 42/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 2/5; 42/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 42/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 3/5; 42/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 42/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 4/5; 42/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 42/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 5/5; 42/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 43/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 1/5; 43/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 43/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 2/5; 43/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 43/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 3/5; 43/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 43/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 4/5; 43/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 43/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 5/5; 43/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 44/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 1/5; 44/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 44/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 2/5; 44/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 44/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 3/5; 44/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 44/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 4/5; 44/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 44/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 5/5; 44/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 45/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 1/5; 45/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 45/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 2/5; 45/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 45/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 3/5; 45/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 45/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 4/5; 45/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 45/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 5/5; 45/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 46/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 46/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 46/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 46/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 46/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 46/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 46/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 46/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 46/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 46/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 47/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 47/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 47/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 47/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 47/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 47/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 47/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 47/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 47/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 47/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 48/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 1/5; 48/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 48/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 2/5; 48/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 48/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 3/5; 48/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 48/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 4/5; 48/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 48/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 5/5; 48/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 49/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 49/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 49/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 49/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 49/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 49/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 49/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 49/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 49/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 49/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 50/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 50/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 50/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 50/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 50/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 50/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 50/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 50/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 50/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 50/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 51/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 1/5; 51/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 2/5; 51/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 2/5; 51/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 51/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 3/5; 51/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 51/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 4/5; 51/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 51/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 5/5; 51/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 52/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 1/5; 52/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 52/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 2/5; 52/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 3/5; 52/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 3/5; 52/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 52/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 4/5; 52/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 52/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 5/5; 52/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 53/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 1/5; 53/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 53/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 2/5; 53/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 53/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 3/5; 53/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 53/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 4/5; 53/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 53/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 5/5; 53/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 54/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 1/5; 54/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 54/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 2/5; 54/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 54/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 3/5; 54/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 54/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 4/5; 54/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 54/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 5/5; 54/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 55/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 55/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 55/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 55/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 55/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 55/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 55/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 55/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 55/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 55/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 56/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 56/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 56/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 56/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 56/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 56/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 56/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 56/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 56/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 56/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 57/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 1/5; 57/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 57/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 2/5; 57/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 57/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 3/5; 57/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 57/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 4/5; 57/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 57/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 5/5; 57/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 58/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 58/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 58/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 58/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 58/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 58/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 58/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 58/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 58/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 58/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 1/5; 59/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 59/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 59/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 59/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 59/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 59/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 59/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 59/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 5/5; 59/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 59/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 60/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 1/5; 60/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 60/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 2/5; 60/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 60/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 3/5; 60/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 4/5; 60/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 4/5; 60/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 5/5; 60/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 5/5; 60/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 61/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 1/5; 61/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 2/5; 61/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 2/5; 61/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 61/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 3/5; 61/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 61/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 4/5; 61/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 61/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 5/5; 61/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 62/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 1/5; 62/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 62/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 2/5; 62/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 62/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 3/5; 62/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 62/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 4/5; 62/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 62/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 5/5; 62/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 1/5; 63/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 1/5; 63/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 63/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 2/5; 63/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 63/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 3/5; 63/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 63/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 4/5; 63/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 63/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 5/5; 63/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 64/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 64/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 64/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 64/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 64/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 64/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 4/5; 64/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 64/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 64/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 64/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 1/5; 65/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 65/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 65/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 65/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 65/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 65/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 65/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 65/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 65/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 65/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 66/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 1/5; 66/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 66/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 2/5; 66/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 66/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 3/5; 66/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 4/5; 66/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 4/5; 66/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 66/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 5/5; 66/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 67/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 67/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 67/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 67/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 67/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 67/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 67/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 67/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 67/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 67/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 68/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 68/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 68/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 68/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 68/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 68/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 68/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 68/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 68/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 68/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 69/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 1/5; 69/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 69/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 2/5; 69/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 69/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 3/5; 69/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 69/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 4/5; 69/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 69/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 5/5; 69/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 70/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 1/5; 70/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 70/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 2/5; 70/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 70/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 3/5; 70/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 70/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 4/5; 70/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 70/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 5/5; 70/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 71/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 1/5; 71/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 71/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 2/5; 71/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 71/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 3/5; 71/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 71/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 4/5; 71/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 71/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 5/5; 71/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 72/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 1/5; 72/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 72/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 2/5; 72/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 72/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 3/5; 72/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.2s\n",
      "[CV 4/5; 72/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 4/5; 72/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 72/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 5/5; 72/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 73/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 73/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 73/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 73/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 73/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 73/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 4/5; 73/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 73/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 73/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 73/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 74/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 74/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 2/5; 74/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 74/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 74/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 74/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 4/5; 74/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 74/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 74/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 74/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 75/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 1/5; 75/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 75/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 2/5; 75/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 75/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 3/5; 75/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 4/5; 75/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 4/5; 75/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 5/5; 75/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 5/5; 75/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 1/5; 76/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 76/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 2/5; 76/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 76/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 76/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 76/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 76/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 76/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 76/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 76/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 77/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 77/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 77/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 77/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 77/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 77/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 77/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 77/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 77/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 77/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 78/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 1/5; 78/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 78/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 2/5; 78/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 78/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 3/5; 78/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 78/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 4/5; 78/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 78/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 5/5; 78/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 79/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 1/5; 79/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 79/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 2/5; 79/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 79/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 3/5; 79/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 79/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 4/5; 79/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 79/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 5/5; 79/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 80/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 1/5; 80/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 80/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 2/5; 80/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 3/5; 80/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 3/5; 80/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 80/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 4/5; 80/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 80/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 5/5; 80/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 81/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 1/5; 81/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 81/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 2/5; 81/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 81/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 3/5; 81/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 81/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 4/5; 81/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 81/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 5/5; 81/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 82/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 82/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 82/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 82/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 82/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 82/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 82/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 82/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 82/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 82/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 83/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 83/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 83/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 83/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 83/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 83/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 83/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 83/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 83/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 83/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 84/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 1/5; 84/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 84/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 2/5; 84/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 84/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 3/5; 84/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 84/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 4/5; 84/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 84/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 5/5; 84/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 85/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 85/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 85/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 85/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 85/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 85/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 85/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 85/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 85/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 85/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 86/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 86/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 86/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 86/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 3/5; 86/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 86/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 86/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 86/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 86/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 86/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 87/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 1/5; 87/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 87/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 2/5; 87/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 87/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 3/5; 87/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 87/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 4/5; 87/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 87/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 5/5; 87/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 88/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 1/5; 88/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 88/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 2/5; 88/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 88/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 3/5; 88/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 88/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 4/5; 88/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 88/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 5/5; 88/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 89/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 1/5; 89/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 89/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 2/5; 89/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 89/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 3/5; 89/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 89/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 4/5; 89/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 89/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 5/5; 89/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 90/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 1/5; 90/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 90/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 2/5; 90/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 90/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 3/5; 90/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 90/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 4/5; 90/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 90/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 5/5; 90/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 91/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 91/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 91/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 91/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 91/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 91/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 91/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 91/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.3s\n",
      "[CV 5/5; 91/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 91/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 1/5; 92/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 92/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 2/5; 92/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 92/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 92/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 92/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 4/5; 92/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 92/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 5/5; 92/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 92/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 93/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 1/5; 93/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 2/5; 93/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 2/5; 93/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.2s\n",
      "[CV 3/5; 93/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 3/5; 93/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.2s\n",
      "[CV 4/5; 93/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 4/5; 93/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.2s\n",
      "[CV 5/5; 93/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 5/5; 93/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 94/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 94/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 94/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 94/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 94/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 94/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 94/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 94/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 94/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 94/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 95/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 95/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 2/5; 95/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 95/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 3/5; 95/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 95/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 4/5; 95/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 95/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 5/5; 95/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 95/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 96/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 1/5; 96/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 96/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 2/5; 96/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 96/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 3/5; 96/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 96/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 4/5; 96/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 96/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 5/5; 96/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 97/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 1/5; 97/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 97/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 2/5; 97/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 97/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 3/5; 97/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 97/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 4/5; 97/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 97/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 5/5; 97/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 98/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 1/5; 98/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 98/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 2/5; 98/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 98/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 3/5; 98/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 98/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 4/5; 98/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 5/5; 98/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 5/5; 98/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 1/5; 99/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 1/5; 99/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 99/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 2/5; 99/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 3/5; 99/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 3/5; 99/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 99/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 4/5; 99/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 99/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 5/5; 99/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 100/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 100/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 100/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 100/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 100/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 100/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 4/5; 100/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 100/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 100/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 100/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 1/5; 101/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 101/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 101/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 101/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 101/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 101/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 101/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 101/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 5/5; 101/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 101/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 102/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 1/5; 102/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 102/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 2/5; 102/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 102/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 3/5; 102/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 4/5; 102/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 4/5; 102/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 102/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 5/5; 102/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 103/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 103/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 103/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 103/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 103/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 103/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 103/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 103/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 103/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 103/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 104/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 104/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 104/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 104/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 104/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 104/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 104/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 104/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 104/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 104/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 1/5; 105/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 1/5; 105/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 2/5; 105/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 2/5; 105/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 105/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 3/5; 105/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 105/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 4/5; 105/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 105/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 5/5; 105/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 1/5; 106/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 1/5; 106/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 106/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 2/5; 106/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 106/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 3/5; 106/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 4/5; 106/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 4/5; 106/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 106/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 5/5; 106/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 107/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 1/5; 107/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 107/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 2/5; 107/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 107/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 3/5; 107/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 107/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 4/5; 107/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 107/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 5/5; 107/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 108/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 1/5; 108/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 108/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 2/5; 108/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 3/5; 108/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 3/5; 108/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 108/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 4/5; 108/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 108/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 5/5; 108/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 109/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 109/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 109/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 109/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 3/5; 109/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 109/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 109/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 109/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 109/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 109/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 110/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 110/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 2/5; 110/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 110/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 110/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 110/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 110/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 110/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 110/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 110/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 111/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 1/5; 111/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 111/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 2/5; 111/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 111/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 3/5; 111/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 4/5; 111/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 4/5; 111/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.2s\n",
      "[CV 5/5; 111/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 5/5; 111/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 112/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 112/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 112/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 112/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 112/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 112/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 4/5; 112/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 112/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 112/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 112/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 113/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 113/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 113/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 113/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 113/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 113/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 113/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 113/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 113/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 113/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 114/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 1/5; 114/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 114/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 2/5; 114/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 114/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 3/5; 114/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 114/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 4/5; 114/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 114/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 5/5; 114/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 115/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 1/5; 115/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 115/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 2/5; 115/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 3/5; 115/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 3/5; 115/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 115/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 4/5; 115/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 115/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 5/5; 115/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 1/5; 116/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 1/5; 116/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 2/5; 116/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 2/5; 116/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 116/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 3/5; 116/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 4/5; 116/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 4/5; 116/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 116/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 5/5; 116/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 1/5; 117/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 1/5; 117/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 117/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 2/5; 117/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 117/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 3/5; 117/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 117/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 4/5; 117/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 117/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 5/5; 117/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 118/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 118/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 118/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 118/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 118/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 118/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 4/5; 118/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 118/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 118/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 118/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 119/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 119/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 2/5; 119/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 119/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 119/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 119/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 119/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 119/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 119/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 119/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 120/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 1/5; 120/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 120/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 2/5; 120/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 120/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 3/5; 120/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 120/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 4/5; 120/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 120/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 5/5; 120/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 121/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 121/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 121/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 121/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 121/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 121/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 121/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 121/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 121/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 121/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 122/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 122/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 122/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 122/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 122/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 122/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 122/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 122/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 122/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 122/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 123/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 1/5; 123/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 2/5; 123/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 2/5; 123/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 3/5; 123/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 3/5; 123/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 4/5; 123/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 4/5; 123/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 123/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 5/5; 123/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 124/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 1/5; 124/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 124/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 2/5; 124/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 124/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 3/5; 124/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 124/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 4/5; 124/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 124/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 5/5; 124/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 125/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 1/5; 125/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 125/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 2/5; 125/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 125/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 3/5; 125/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 125/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 4/5; 125/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 125/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 5/5; 125/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 126/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 1/5; 126/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 126/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 2/5; 126/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 126/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 3/5; 126/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 126/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 4/5; 126/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 126/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 5/5; 126/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 127/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 127/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 127/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 127/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 127/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 127/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 127/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 127/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 5/5; 127/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 127/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 128/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 128/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 128/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 128/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 128/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 128/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 128/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 128/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 128/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 128/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 129/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 1/5; 129/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 129/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 2/5; 129/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 129/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 3/5; 129/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 129/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 4/5; 129/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 129/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 5/5; 129/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 130/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 130/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 130/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 130/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 130/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 130/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 130/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 130/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 130/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 130/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 131/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 131/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 131/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 131/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 131/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 131/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 4/5; 131/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 131/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 131/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 131/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 132/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 1/5; 132/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 132/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 2/5; 132/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 132/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 3/5; 132/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 132/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 4/5; 132/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 132/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 5/5; 132/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 133/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 1/5; 133/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 133/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 2/5; 133/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 133/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 3/5; 133/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 133/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 4/5; 133/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 133/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 5/5; 133/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 134/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 1/5; 134/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 134/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 2/5; 134/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 134/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 3/5; 134/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 134/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 4/5; 134/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 134/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 5/5; 134/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 135/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 1/5; 135/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 2/5; 135/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 2/5; 135/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 3/5; 135/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 3/5; 135/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 135/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 4/5; 135/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 135/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 5/5; 135/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 136/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 136/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 136/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 136/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 136/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 136/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 136/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 136/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 136/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 136/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 137/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 137/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 137/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 137/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 137/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 137/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 137/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 137/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 5/5; 137/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 137/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 138/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 1/5; 138/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 138/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 2/5; 138/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 138/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 3/5; 138/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 138/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 4/5; 138/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 138/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 5/5; 138/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.2s\n",
      "[CV 1/5; 139/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 139/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 2/5; 139/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 139/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 139/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 139/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 139/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 139/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 139/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 139/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 140/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 140/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 140/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 140/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 140/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 140/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 140/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 140/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 140/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 140/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 141/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 1/5; 141/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 141/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 2/5; 141/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 141/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 3/5; 141/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 141/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 4/5; 141/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 141/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 5/5; 141/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 142/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 1/5; 142/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 142/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 2/5; 142/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 142/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 3/5; 142/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 4/5; 142/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 4/5; 142/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 142/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 5/5; 142/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 143/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 1/5; 143/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 2/5; 143/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 2/5; 143/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 3/5; 143/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 3/5; 143/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.2s\n",
      "[CV 4/5; 143/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 4/5; 143/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 5/5; 143/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 5/5; 143/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 144/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 1/5; 144/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 144/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 2/5; 144/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 144/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 3/5; 144/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 144/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 4/5; 144/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 144/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 5/5; 144/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 145/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 145/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 145/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 145/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 145/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 145/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 4/5; 145/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 145/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 145/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 145/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 146/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 146/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 146/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 146/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 3/5; 146/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 146/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 4/5; 146/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 146/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.2s\n",
      "[CV 5/5; 146/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 146/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 1/5; 147/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 1/5; 147/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 2/5; 147/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 2/5; 147/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 3/5; 147/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 3/5; 147/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 4/5; 147/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 4/5; 147/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 5/5; 147/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 5/5; 147/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 1/5; 148/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 148/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 2/5; 148/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 148/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 3/5; 148/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 148/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 4/5; 148/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 148/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 5/5; 148/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 148/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 1/5; 149/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 149/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 149/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 149/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 149/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 149/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 149/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 149/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 149/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 149/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 150/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 1/5; 150/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 2/5; 150/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 2/5; 150/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.3s\n",
      "[CV 3/5; 150/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 3/5; 150/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 150/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 4/5; 150/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 150/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 5/5; 150/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 151/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 1/5; 151/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 2/5; 151/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 2/5; 151/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.2s\n",
      "[CV 3/5; 151/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 3/5; 151/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 151/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 4/5; 151/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 151/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 5/5; 151/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 152/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 1/5; 152/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 152/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 2/5; 152/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 152/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 3/5; 152/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 152/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 4/5; 152/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 152/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 5/5; 152/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 1/5; 153/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 1/5; 153/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 2/5; 153/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 2/5; 153/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 153/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 3/5; 153/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 153/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 4/5; 153/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 153/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 5/5; 153/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 154/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 154/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 154/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 154/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 154/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 154/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.2s\n",
      "[CV 4/5; 154/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 154/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.2s\n",
      "[CV 5/5; 154/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 154/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.2s\n",
      "[CV 1/5; 155/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 155/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.3s\n",
      "[CV 2/5; 155/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 155/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 3/5; 155/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 155/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.3s\n",
      "[CV 4/5; 155/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 155/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.3s\n",
      "[CV 5/5; 155/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 155/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.3s\n",
      "[CV 1/5; 156/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 1/5; 156/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.3s\n",
      "[CV 2/5; 156/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 2/5; 156/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 3/5; 156/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 3/5; 156/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 156/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 4/5; 156/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 156/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 5/5; 156/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 1/5; 157/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 157/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 2/5; 157/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 157/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 3/5; 157/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 157/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 157/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 157/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 157/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 157/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 1/5; 158/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 158/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 158/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 158/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 3/5; 158/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 158/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 4/5; 158/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 158/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 5/5; 158/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 158/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 159/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 1/5; 159/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 159/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 2/5; 159/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 3/5; 159/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 3/5; 159/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 159/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 4/5; 159/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 5/5; 159/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 5/5; 159/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 1/5; 160/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 1/5; 160/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 160/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 2/5; 160/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 160/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 3/5; 160/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 160/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 4/5; 160/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 160/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 5/5; 160/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 161/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 1/5; 161/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 161/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 2/5; 161/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 161/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 3/5; 161/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 161/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 4/5; 161/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 161/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 5/5; 161/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 1/5; 162/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 1/5; 162/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 162/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 2/5; 162/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 162/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 3/5; 162/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 162/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 4/5; 162/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 162/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 5/5; 162/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 163/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 163/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 163/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 163/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 3/5; 163/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 163/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 163/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 163/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 5/5; 163/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 163/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.2s\n",
      "[CV 1/5; 164/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 164/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 2/5; 164/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 164/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 164/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 164/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 164/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 164/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 164/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 164/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 165/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 1/5; 165/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 165/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 2/5; 165/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 3/5; 165/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 3/5; 165/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 165/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 4/5; 165/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 165/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 5/5; 165/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 166/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 166/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 166/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 166/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 166/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 166/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 166/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 166/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 166/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 166/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 167/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 167/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 167/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 167/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 167/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 167/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 167/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 167/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 167/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 167/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 168/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 1/5; 168/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 168/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 2/5; 168/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 168/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 3/5; 168/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 4/5; 168/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 4/5; 168/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 5/5; 168/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 5/5; 168/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 169/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 1/5; 169/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 169/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 2/5; 169/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 169/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 3/5; 169/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 169/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 4/5; 169/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 169/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 5/5; 169/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 170/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 1/5; 170/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 2/5; 170/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 2/5; 170/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 170/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 3/5; 170/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 170/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 4/5; 170/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 170/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 5/5; 170/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 171/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 1/5; 171/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 171/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 2/5; 171/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 171/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 3/5; 171/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 4/5; 171/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 4/5; 171/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 171/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 5/5; 171/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 172/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 172/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 172/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 172/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 172/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 172/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 172/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 172/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 172/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 172/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 173/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 173/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 173/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 173/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 173/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 173/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 173/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 173/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 173/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 173/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 1/5; 174/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 1/5; 174/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 174/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 2/5; 174/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 174/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 3/5; 174/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 4/5; 174/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 4/5; 174/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 174/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 5/5; 174/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 175/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 175/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 175/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 175/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 175/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 175/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 175/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 175/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 175/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 175/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 176/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 176/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 176/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 176/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 176/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 176/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 176/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 176/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 176/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 176/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 177/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 1/5; 177/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 177/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 2/5; 177/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 177/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 3/5; 177/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 4/5; 177/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 4/5; 177/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 177/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 5/5; 177/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 178/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 1/5; 178/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 2/5; 178/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 2/5; 178/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 178/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 3/5; 178/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 178/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 4/5; 178/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 178/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 5/5; 178/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 179/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 1/5; 179/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 179/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 2/5; 179/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 3/5; 179/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 3/5; 179/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 179/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 4/5; 179/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 179/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 5/5; 179/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 180/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 1/5; 180/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 180/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 2/5; 180/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 3/5; 180/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 3/5; 180/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 180/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 4/5; 180/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 180/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 5/5; 180/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 181/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 181/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 2/5; 181/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 181/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.2s\n",
      "[CV 3/5; 181/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 181/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 4/5; 181/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 181/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 5/5; 181/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 181/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 1/5; 182/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 182/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 182/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 182/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 182/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 182/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 182/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 182/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 182/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 182/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 183/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 1/5; 183/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 2/5; 183/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 2/5; 183/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 183/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 3/5; 183/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 183/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 4/5; 183/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.2s\n",
      "[CV 5/5; 183/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 5/5; 183/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 184/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 184/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 184/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 184/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 184/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 184/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 184/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 184/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 184/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 184/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 185/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 185/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 185/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 185/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 185/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 185/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 4/5; 185/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 185/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 185/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 185/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 186/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 1/5; 186/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 186/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 2/5; 186/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 186/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 3/5; 186/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 186/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 4/5; 186/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 5/5; 186/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 5/5; 186/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 1/5; 187/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 1/5; 187/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 187/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 2/5; 187/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 187/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 3/5; 187/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 187/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 4/5; 187/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 187/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 5/5; 187/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 188/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 1/5; 188/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 188/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 2/5; 188/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 188/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 3/5; 188/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 188/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 4/5; 188/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 188/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 5/5; 188/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 189/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 1/5; 189/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 189/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 2/5; 189/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 189/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 3/5; 189/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 4/5; 189/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 4/5; 189/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 189/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 5/5; 189/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 190/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 190/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 190/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 190/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.2s\n",
      "[CV 3/5; 190/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 190/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 190/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 190/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 190/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 190/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 191/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 191/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 191/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 191/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 191/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 191/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 191/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 191/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 191/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 191/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 192/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 1/5; 192/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 2/5; 192/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 2/5; 192/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 192/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 3/5; 192/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 192/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 4/5; 192/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 192/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 5/5; 192/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 193/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 193/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 193/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 193/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 193/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 193/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 193/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 193/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 193/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 193/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 194/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 194/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 194/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 194/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 194/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 194/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 194/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 194/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 194/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 194/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 1/5; 195/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 1/5; 195/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 195/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 2/5; 195/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 195/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 3/5; 195/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 195/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 4/5; 195/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 195/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 5/5; 195/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 196/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 1/5; 196/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 196/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 2/5; 196/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 196/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 3/5; 196/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 196/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 4/5; 196/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 196/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 5/5; 196/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 197/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 1/5; 197/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 197/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 2/5; 197/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 197/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 3/5; 197/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 197/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 4/5; 197/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 5/5; 197/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 5/5; 197/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 198/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 1/5; 198/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 198/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 2/5; 198/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 198/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 3/5; 198/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 198/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 4/5; 198/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 5/5; 198/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 5/5; 198/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 1/5; 199/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 199/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 199/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 199/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 199/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 199/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 199/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 199/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 199/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 199/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 200/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 200/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 200/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 200/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 3/5; 200/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 200/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 200/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 200/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 5/5; 200/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 200/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 201/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 1/5; 201/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 201/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 2/5; 201/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 201/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 3/5; 201/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 201/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 4/5; 201/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 201/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 5/5; 201/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 202/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 202/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 202/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 202/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 202/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 202/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 202/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 202/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 202/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 202/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 203/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 203/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 203/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 203/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 203/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 203/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 203/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 203/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 203/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 203/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 204/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 1/5; 204/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 204/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 2/5; 204/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 204/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 3/5; 204/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 204/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 4/5; 204/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 204/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 5/5; 204/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 205/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 1/5; 205/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 205/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 2/5; 205/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 205/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 3/5; 205/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 205/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 4/5; 205/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 205/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 5/5; 205/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 206/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 1/5; 206/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 206/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 2/5; 206/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 3/5; 206/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 3/5; 206/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 206/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 4/5; 206/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 206/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 5/5; 206/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 1/5; 207/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 1/5; 207/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 207/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 2/5; 207/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 207/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 3/5; 207/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 207/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 4/5; 207/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 207/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 5/5; 207/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 208/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 208/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 208/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 208/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 208/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 208/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 4/5; 208/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 208/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.2s\n",
      "[CV 5/5; 208/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 208/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.2s\n",
      "[CV 1/5; 209/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 209/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 209/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 209/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 209/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 209/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 209/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 209/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 209/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 209/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 210/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 1/5; 210/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 210/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 2/5; 210/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 210/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 3/5; 210/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 210/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 4/5; 210/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 210/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 5/5; 210/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 211/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 211/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 211/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 211/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 211/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 211/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 211/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 211/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 211/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 211/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 212/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 212/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 2/5; 212/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 212/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 212/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 212/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 212/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 212/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 212/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 212/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 213/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 1/5; 213/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 213/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 2/5; 213/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 213/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 3/5; 213/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 213/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 4/5; 213/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 213/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 5/5; 213/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 214/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 1/5; 214/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 214/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 2/5; 214/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 214/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 3/5; 214/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 214/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 4/5; 214/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 5/5; 214/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 5/5; 214/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 215/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 1/5; 215/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 215/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 2/5; 215/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 215/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 3/5; 215/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 215/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 4/5; 215/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 215/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 5/5; 215/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 216/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 1/5; 216/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 216/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 2/5; 216/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 216/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 3/5; 216/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 216/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 4/5; 216/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 216/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 5/5; 216/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 1/5; 217/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 217/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 2/5; 217/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 217/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 217/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 217/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 217/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 217/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 217/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 217/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 218/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 218/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 218/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 218/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 218/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 218/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 218/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 218/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 218/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 218/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 1/5; 219/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 1/5; 219/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 2/5; 219/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 2/5; 219/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 219/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 3/5; 219/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 219/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 4/5; 219/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 5/5; 219/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 5/5; 219/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 220/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 220/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 220/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 220/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 220/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 220/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 220/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 220/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 220/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 220/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 221/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 221/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 221/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 221/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 221/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 221/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 4/5; 221/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 221/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 221/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 221/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 222/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 1/5; 222/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 222/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 2/5; 222/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 222/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 3/5; 222/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 222/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 4/5; 222/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 222/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 5/5; 222/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 223/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 1/5; 223/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 223/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 2/5; 223/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 3/5; 223/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 3/5; 223/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 223/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 4/5; 223/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 223/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 5/5; 223/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 224/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 1/5; 224/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 224/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 2/5; 224/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 224/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 3/5; 224/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 224/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 4/5; 224/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 224/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 5/5; 224/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 225/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 1/5; 225/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 225/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 2/5; 225/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 3/5; 225/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 3/5; 225/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 225/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 4/5; 225/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 225/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 5/5; 225/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 226/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 226/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 226/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 226/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 226/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 226/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 226/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 226/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 226/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 226/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 227/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 227/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 227/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 227/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 227/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 227/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 227/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 227/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 5/5; 227/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 227/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 228/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 1/5; 228/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 228/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 2/5; 228/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 228/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 3/5; 228/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 228/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 4/5; 228/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 228/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 5/5; 228/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 229/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 229/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 229/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 229/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 229/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 229/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 229/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 229/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 229/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 229/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 230/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 230/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 2/5; 230/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 230/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 230/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 230/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.3s\n",
      "[CV 4/5; 230/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 230/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 230/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 230/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 231/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 1/5; 231/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 231/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 2/5; 231/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 231/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 3/5; 231/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 231/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 4/5; 231/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 231/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 5/5; 231/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 232/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 1/5; 232/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 232/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 2/5; 232/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 3/5; 232/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 3/5; 232/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 232/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 4/5; 232/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 232/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 5/5; 232/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 233/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 1/5; 233/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 233/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 2/5; 233/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 233/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 3/5; 233/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 233/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 4/5; 233/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 233/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 5/5; 233/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 234/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 1/5; 234/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 234/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 2/5; 234/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 234/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 3/5; 234/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 234/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 4/5; 234/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 234/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 5/5; 234/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 1/5; 235/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 235/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 235/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 235/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 235/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 235/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 235/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 235/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 235/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 235/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 236/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 236/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 236/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 236/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 236/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 236/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 236/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 236/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 236/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 236/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 237/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 1/5; 237/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 237/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 2/5; 237/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 237/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 3/5; 237/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 237/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 4/5; 237/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 5/5; 237/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 5/5; 237/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 238/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 238/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 238/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 238/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 238/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 238/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 238/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 238/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 238/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 238/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 239/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 239/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 239/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 239/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 239/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 239/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 239/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 239/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 239/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 239/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 240/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 1/5; 240/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 240/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 2/5; 240/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 3/5; 240/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 3/5; 240/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 240/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 4/5; 240/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 240/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 5/5; 240/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 241/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 1/5; 241/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 241/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 2/5; 241/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 241/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 3/5; 241/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 241/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 4/5; 241/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 241/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 5/5; 241/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 242/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 1/5; 242/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 242/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 2/5; 242/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 242/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 3/5; 242/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 242/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 4/5; 242/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 242/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 5/5; 242/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 243/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 1/5; 243/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 2/5; 243/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 2/5; 243/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 243/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 3/5; 243/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 243/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 4/5; 243/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 243/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 5/5; 243/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 244/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 244/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 244/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 244/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 244/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 244/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 244/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 244/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 244/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 244/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 245/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 245/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 245/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 245/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 245/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 245/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 245/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 245/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 245/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 245/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 246/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 1/5; 246/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 2/5; 246/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 2/5; 246/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 246/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 3/5; 246/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 246/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 4/5; 246/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 246/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 5/5; 246/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 247/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 247/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 247/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 247/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 247/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 247/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 247/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 247/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 247/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 247/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 248/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 248/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 248/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 248/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 248/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 248/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 4/5; 248/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 248/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 248/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 248/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 249/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 1/5; 249/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 249/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 2/5; 249/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 249/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 3/5; 249/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 249/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 4/5; 249/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 249/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 5/5; 249/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 250/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 1/5; 250/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 250/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 2/5; 250/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 250/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 3/5; 250/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 250/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 4/5; 250/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 250/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 5/5; 250/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 1/5; 251/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 1/5; 251/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 251/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 2/5; 251/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 251/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 3/5; 251/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 251/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 4/5; 251/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 251/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 5/5; 251/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 252/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 1/5; 252/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 252/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 2/5; 252/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 252/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 3/5; 252/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 252/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 4/5; 252/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 252/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 5/5; 252/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 253/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 253/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 253/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 253/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 253/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 253/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 4/5; 253/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 253/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 253/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 253/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 254/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 254/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 254/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 254/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 254/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 254/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 254/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 254/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 254/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 254/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 255/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 1/5; 255/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 255/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 2/5; 255/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 255/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 3/5; 255/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 255/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 4/5; 255/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 255/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 5/5; 255/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 256/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 256/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 256/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 256/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 256/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 256/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 4/5; 256/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 256/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 256/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 256/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 257/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 257/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 257/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 257/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 257/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 257/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 257/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 257/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 257/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 257/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 258/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 1/5; 258/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 258/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 2/5; 258/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 258/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 3/5; 258/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 258/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 4/5; 258/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 258/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 5/5; 258/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 1/5; 259/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 1/5; 259/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 259/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 2/5; 259/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 259/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 3/5; 259/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 259/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 4/5; 259/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 259/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 5/5; 259/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 260/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 1/5; 260/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 260/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 2/5; 260/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 260/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 3/5; 260/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 260/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 4/5; 260/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 260/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 5/5; 260/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 1/5; 261/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 1/5; 261/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 2/5; 261/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 2/5; 261/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 3/5; 261/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 3/5; 261/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 4/5; 261/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 4/5; 261/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 261/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 5/5; 261/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 262/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 262/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 262/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 262/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 262/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 262/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 262/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 262/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 262/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 262/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 263/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 263/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 263/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 263/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 263/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 263/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 263/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 263/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 5/5; 263/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 263/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 264/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 1/5; 264/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 264/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 2/5; 264/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 264/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 3/5; 264/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 264/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 4/5; 264/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 264/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 5/5; 264/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 265/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 265/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 265/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 265/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 265/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 265/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 265/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 265/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 265/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 265/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 266/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 266/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 266/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 266/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.2s\n",
      "[CV 3/5; 266/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 266/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 4/5; 266/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 266/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 266/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 266/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 267/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 1/5; 267/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 267/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 2/5; 267/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 267/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 3/5; 267/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 267/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 4/5; 267/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 267/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 5/5; 267/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 1/5; 268/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 1/5; 268/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 268/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 2/5; 268/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 268/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 3/5; 268/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 268/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 4/5; 268/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 268/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 5/5; 268/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 269/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 1/5; 269/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.2s\n",
      "[CV 2/5; 269/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 2/5; 269/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 269/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 3/5; 269/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 4/5; 269/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 4/5; 269/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 269/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 5/5; 269/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 270/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 1/5; 270/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 2/5; 270/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 2/5; 270/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 270/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 3/5; 270/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 270/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 4/5; 270/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 270/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 5/5; 270/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 271/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 271/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 271/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 271/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 271/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 271/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 271/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 271/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 271/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 271/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 1/5; 272/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 272/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 272/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 272/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 272/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 272/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 272/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 272/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 272/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 272/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 273/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 1/5; 273/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 273/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 2/5; 273/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 273/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 3/5; 273/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 273/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 4/5; 273/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 273/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 5/5; 273/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 274/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 274/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 2/5; 274/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 274/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 274/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 274/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 274/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 274/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 274/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 274/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 275/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 275/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 275/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 275/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 275/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 275/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 275/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 275/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 275/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 275/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 276/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 1/5; 276/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 2/5; 276/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 2/5; 276/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 276/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 3/5; 276/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 276/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 4/5; 276/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 276/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 5/5; 276/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 277/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 1/5; 277/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 277/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 2/5; 277/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 277/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 3/5; 277/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 277/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 4/5; 277/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 5/5; 277/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 5/5; 277/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.2s\n",
      "[CV 1/5; 278/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 1/5; 278/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 278/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 2/5; 278/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 278/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 3/5; 278/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 278/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 4/5; 278/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 278/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 5/5; 278/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 279/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 1/5; 279/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 279/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 2/5; 279/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 279/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 3/5; 279/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 279/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 4/5; 279/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 279/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 5/5; 279/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 280/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 280/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 2/5; 280/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 280/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 280/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 280/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 280/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 280/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 280/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 280/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 281/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 281/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 281/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 281/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 281/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 281/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 281/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 281/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 281/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 281/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 282/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 1/5; 282/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 282/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 2/5; 282/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 282/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 3/5; 282/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 282/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 4/5; 282/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 282/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 5/5; 282/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 283/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 283/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 2/5; 283/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 283/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 283/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 283/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 4/5; 283/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 283/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 283/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 283/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 284/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 284/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 284/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 284/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 284/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 284/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 284/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 284/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 284/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 284/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 285/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 1/5; 285/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 285/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 2/5; 285/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 285/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 3/5; 285/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 285/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 4/5; 285/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 285/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 5/5; 285/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 286/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 1/5; 286/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 286/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 2/5; 286/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 3/5; 286/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 3/5; 286/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 286/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 4/5; 286/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 286/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 5/5; 286/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 1/5; 287/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 1/5; 287/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 287/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 2/5; 287/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 3/5; 287/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 3/5; 287/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 287/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 4/5; 287/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 287/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 5/5; 287/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 288/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 1/5; 288/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 288/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 2/5; 288/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 3/5; 288/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 3/5; 288/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 288/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 4/5; 288/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 288/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 5/5; 288/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 289/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 289/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 289/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 289/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 289/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 289/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 289/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 289/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 289/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 289/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 1/5; 290/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 290/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 290/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 290/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 290/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 290/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 290/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 290/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 290/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 290/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 291/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 1/5; 291/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 291/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 2/5; 291/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 3/5; 291/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 3/5; 291/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 4/5; 291/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 4/5; 291/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 291/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 5/5; 291/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 1/5; 292/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 292/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 292/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 292/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 292/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 292/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 292/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 292/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 292/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 292/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 293/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 293/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 293/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 293/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 293/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 293/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 293/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 293/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 293/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 293/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 294/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 1/5; 294/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 2/5; 294/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 2/5; 294/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 294/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 3/5; 294/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.2s\n",
      "[CV 4/5; 294/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 4/5; 294/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 5/5; 294/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 5/5; 294/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 295/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 1/5; 295/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 295/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 2/5; 295/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 295/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 3/5; 295/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 295/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 4/5; 295/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 295/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 5/5; 295/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 296/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 1/5; 296/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 296/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 2/5; 296/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 296/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 3/5; 296/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 296/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 4/5; 296/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 296/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 5/5; 296/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 297/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 1/5; 297/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 297/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 2/5; 297/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 297/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 3/5; 297/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 297/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 4/5; 297/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 297/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 5/5; 297/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 298/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 298/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 2/5; 298/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 298/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 3/5; 298/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 298/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 298/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 298/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 298/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 298/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 299/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 299/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 299/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 299/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 299/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 299/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 299/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 299/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 299/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 299/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 300/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 1/5; 300/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 300/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 2/5; 300/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 3/5; 300/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 3/5; 300/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 300/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 4/5; 300/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 300/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 5/5; 300/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 301/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 301/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 301/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 301/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 301/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 301/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 301/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 301/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 301/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 301/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 302/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 302/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 302/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 302/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 302/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 302/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 302/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 302/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 5/5; 302/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 302/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 303/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 1/5; 303/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 303/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 2/5; 303/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 303/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 3/5; 303/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 303/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 4/5; 303/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 303/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 5/5; 303/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 304/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 1/5; 304/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 304/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 2/5; 304/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 3/5; 304/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 3/5; 304/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 4/5; 304/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 4/5; 304/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 5/5; 304/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 5/5; 304/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 305/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 1/5; 305/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 305/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 2/5; 305/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 305/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 3/5; 305/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 305/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 4/5; 305/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 305/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 5/5; 305/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 306/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 1/5; 306/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 306/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 2/5; 306/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 306/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 3/5; 306/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 306/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 4/5; 306/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 306/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 5/5; 306/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 307/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 307/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 307/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 307/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 307/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 307/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 307/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 307/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.3s\n",
      "[CV 5/5; 307/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 307/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 1/5; 308/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 308/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 2/5; 308/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 308/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 308/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 308/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 308/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 308/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 308/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 308/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 309/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 1/5; 309/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 309/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 2/5; 309/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 309/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 3/5; 309/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 309/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 4/5; 309/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 309/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 5/5; 309/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 310/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 310/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 310/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 310/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 3/5; 310/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 310/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 310/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 310/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 310/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 310/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 311/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 311/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 311/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 311/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 311/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 311/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 311/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 311/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 311/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 311/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 312/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 1/5; 312/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 312/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 2/5; 312/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 3/5; 312/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 3/5; 312/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 312/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 4/5; 312/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 312/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 5/5; 312/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 313/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 1/5; 313/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 313/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 2/5; 313/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 313/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 3/5; 313/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 313/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 4/5; 313/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 313/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 5/5; 313/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 314/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 1/5; 314/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 314/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 2/5; 314/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 3/5; 314/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 3/5; 314/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 314/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 4/5; 314/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 314/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 5/5; 314/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 315/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 1/5; 315/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 315/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 2/5; 315/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 3/5; 315/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 3/5; 315/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 315/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 4/5; 315/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 315/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 5/5; 315/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 316/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 316/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 316/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 316/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 316/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 316/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 316/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 316/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 5/5; 316/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 316/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 317/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 317/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 317/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 317/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 3/5; 317/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 317/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 317/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 317/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 317/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 317/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 318/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 1/5; 318/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 318/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 2/5; 318/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 318/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 3/5; 318/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 318/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 4/5; 318/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 5/5; 318/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 5/5; 318/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 319/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 319/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 319/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 319/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 319/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 319/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 319/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 319/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 5/5; 319/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 319/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 320/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 320/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 320/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 320/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 320/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 320/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 4/5; 320/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 320/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 320/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 320/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 321/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 1/5; 321/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 321/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 2/5; 321/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 321/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 3/5; 321/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 321/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 4/5; 321/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 321/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 5/5; 321/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 322/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 1/5; 322/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 322/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 2/5; 322/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 322/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 3/5; 322/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 4/5; 322/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 4/5; 322/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 322/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 5/5; 322/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 323/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 1/5; 323/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 323/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 2/5; 323/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 3/5; 323/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 3/5; 323/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 4/5; 323/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 4/5; 323/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 5/5; 323/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 5/5; 323/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.3s\n",
      "[CV 1/5; 324/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 1/5; 324/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 2/5; 324/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 2/5; 324/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 3/5; 324/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 3/5; 324/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 4/5; 324/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 4/5; 324/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 324/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 5/5; 324/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 325/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 325/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.2s\n",
      "[CV 2/5; 325/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 325/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 3/5; 325/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 325/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 4/5; 325/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 325/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.3s\n",
      "[CV 5/5; 325/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 325/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 1/5; 326/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 326/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 2/5; 326/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 326/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 3/5; 326/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 326/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 4/5; 326/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 326/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 326/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 326/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 327/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 1/5; 327/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 327/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 2/5; 327/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 327/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 3/5; 327/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 327/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 4/5; 327/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 327/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 5/5; 327/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 328/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 328/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 328/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 328/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 328/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 328/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 328/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 328/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 5/5; 328/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 328/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 329/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 329/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 329/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 329/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 329/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 329/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 329/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 329/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 329/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 329/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 330/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 1/5; 330/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 330/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 2/5; 330/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 3/5; 330/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 3/5; 330/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 4/5; 330/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 4/5; 330/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 330/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 5/5; 330/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 331/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 1/5; 331/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 331/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 2/5; 331/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 331/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 3/5; 331/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 331/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 4/5; 331/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 331/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 5/5; 331/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 1/5; 332/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 1/5; 332/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 332/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 2/5; 332/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 332/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 3/5; 332/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 4/5; 332/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 4/5; 332/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.2s\n",
      "[CV 5/5; 332/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 5/5; 332/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.3s\n",
      "[CV 1/5; 333/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 1/5; 333/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.3s\n",
      "[CV 2/5; 333/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 2/5; 333/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 3/5; 333/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 3/5; 333/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.2s\n",
      "[CV 4/5; 333/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 4/5; 333/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.2s\n",
      "[CV 5/5; 333/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 5/5; 333/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.2s\n",
      "[CV 1/5; 334/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 334/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 2/5; 334/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 334/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 3/5; 334/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 334/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 4/5; 334/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 334/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 334/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 334/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 335/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 335/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 335/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 335/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 335/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 335/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 335/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 335/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 335/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 335/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 336/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 1/5; 336/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 2/5; 336/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 2/5; 336/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 3/5; 336/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 3/5; 336/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 336/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 4/5; 336/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 336/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 5/5; 336/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 337/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 337/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 337/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 337/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 337/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 337/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 337/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 337/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 337/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 337/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 1/5; 338/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 338/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 338/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 338/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 338/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 338/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 338/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 338/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 338/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 338/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 339/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 1/5; 339/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 339/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 2/5; 339/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 339/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 3/5; 339/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 4/5; 339/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 4/5; 339/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 5/5; 339/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 5/5; 339/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 340/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 1/5; 340/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 340/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 2/5; 340/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 340/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 3/5; 340/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 340/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 4/5; 340/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 340/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 5/5; 340/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 341/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 1/5; 341/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 341/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 2/5; 341/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 3/5; 341/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 3/5; 341/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 341/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 4/5; 341/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 341/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 5/5; 341/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 342/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 1/5; 342/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 342/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 2/5; 342/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 342/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 3/5; 342/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 342/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 4/5; 342/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 342/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 5/5; 342/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 1/5; 343/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 343/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 343/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 343/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 343/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 343/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 343/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 343/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 343/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 343/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 344/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 344/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 344/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 344/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 344/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 344/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 344/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 344/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.2s\n",
      "[CV 5/5; 344/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 344/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 1/5; 345/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 1/5; 345/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 345/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 2/5; 345/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 345/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 3/5; 345/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 345/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 4/5; 345/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 5/5; 345/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 5/5; 345/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 346/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 346/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.2s\n",
      "[CV 2/5; 346/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 346/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.3s\n",
      "[CV 3/5; 346/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 346/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 346/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 346/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 346/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 346/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 347/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 347/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 347/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 347/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 347/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 347/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 347/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 347/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 5/5; 347/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 347/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 348/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 1/5; 348/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 348/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 2/5; 348/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 348/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 3/5; 348/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 348/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 4/5; 348/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 5/5; 348/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 5/5; 348/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 349/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 1/5; 349/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 2/5; 349/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 2/5; 349/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 349/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 3/5; 349/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 4/5; 349/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 4/5; 349/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 349/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 5/5; 349/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 350/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 1/5; 350/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 350/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 2/5; 350/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 350/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 3/5; 350/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 350/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 4/5; 350/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 5/5; 350/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 5/5; 350/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 351/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 1/5; 351/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 351/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 2/5; 351/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 351/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 3/5; 351/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 351/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 4/5; 351/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 351/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 5/5; 351/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 352/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 352/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 352/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 352/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 352/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 352/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 4/5; 352/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 352/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.2s\n",
      "[CV 5/5; 352/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 352/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.2s\n",
      "[CV 1/5; 353/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 353/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 2/5; 353/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 353/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.2s\n",
      "[CV 3/5; 353/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 353/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.2s\n",
      "[CV 4/5; 353/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 353/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 5/5; 353/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 353/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.2s\n",
      "[CV 1/5; 354/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 1/5; 354/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 2/5; 354/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 2/5; 354/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 354/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 3/5; 354/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 354/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 4/5; 354/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 354/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 5/5; 354/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 1/5; 355/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 355/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.2s\n",
      "[CV 2/5; 355/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 355/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 3/5; 355/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 355/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.2s\n",
      "[CV 4/5; 355/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 355/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.2s\n",
      "[CV 5/5; 355/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 355/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.2s\n",
      "[CV 1/5; 356/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 356/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 2/5; 356/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 356/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 356/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 356/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 4/5; 356/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 356/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 356/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 356/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 357/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 1/5; 357/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 357/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 2/5; 357/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 357/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 3/5; 357/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 4/5; 357/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 4/5; 357/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 5/5; 357/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 5/5; 357/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.2s\n",
      "[CV 1/5; 358/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 1/5; 358/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.3s\n",
      "[CV 2/5; 358/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 2/5; 358/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.2s\n",
      "[CV 3/5; 358/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 3/5; 358/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 4/5; 358/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 4/5; 358/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 5/5; 358/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 5/5; 358/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 1/5; 359/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 1/5; 359/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 2/5; 359/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 2/5; 359/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 3/5; 359/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 3/5; 359/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 4/5; 359/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 4/5; 359/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 5/5; 359/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 5/5; 359/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 1/5; 360/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 1/5; 360/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.2s\n",
      "[CV 2/5; 360/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 2/5; 360/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.2s\n",
      "[CV 3/5; 360/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 3/5; 360/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 4/5; 360/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 4/5; 360/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 5/5; 360/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 5/5; 360/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 1/5; 361/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 361/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 2/5; 361/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 361/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.2s\n",
      "[CV 3/5; 361/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 361/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 4/5; 361/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 361/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 5/5; 361/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 361/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 1/5; 362/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 362/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 2/5; 362/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 362/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 3/5; 362/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 362/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 4/5; 362/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 362/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.2s\n",
      "[CV 5/5; 362/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 362/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.3s\n",
      "[CV 1/5; 363/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 1/5; 363/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.2s\n",
      "[CV 2/5; 363/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 2/5; 363/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.2s\n",
      "[CV 3/5; 363/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 3/5; 363/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 4/5; 363/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 4/5; 363/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 363/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 5/5; 363/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 364/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 364/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 364/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 364/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 3/5; 364/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 364/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 364/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 364/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 364/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 364/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 1/5; 365/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 365/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 365/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 365/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 365/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 365/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 365/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 365/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 365/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 365/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 366/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 1/5; 366/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 366/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 2/5; 366/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 366/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 3/5; 366/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 366/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 4/5; 366/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 366/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 5/5; 366/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 367/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 1/5; 367/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 367/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 2/5; 367/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 367/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 3/5; 367/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 367/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 4/5; 367/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 367/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 5/5; 367/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 368/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 1/5; 368/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 368/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 2/5; 368/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 368/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 3/5; 368/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 368/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 4/5; 368/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 368/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 5/5; 368/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 369/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 1/5; 369/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 369/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 2/5; 369/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 369/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 3/5; 369/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 369/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 4/5; 369/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 369/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 5/5; 369/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 370/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 370/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 370/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 370/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 370/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 370/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 370/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 370/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 5/5; 370/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 370/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 371/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 371/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 2/5; 371/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 371/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 3/5; 371/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 371/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 371/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 371/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 371/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 371/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 372/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 1/5; 372/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 372/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 2/5; 372/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 372/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 3/5; 372/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 372/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 4/5; 372/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 372/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 5/5; 372/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 373/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 373/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 373/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 373/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 373/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 373/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 373/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 373/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 373/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 373/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 374/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 374/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 374/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 374/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 374/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 374/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 374/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 374/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 374/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 374/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 375/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 1/5; 375/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 375/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 2/5; 375/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 375/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 3/5; 375/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 375/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 4/5; 375/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 375/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 5/5; 375/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 376/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 1/5; 376/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 376/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 2/5; 376/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 376/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 3/5; 376/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 376/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 4/5; 376/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 376/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 5/5; 376/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 1/5; 377/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 1/5; 377/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 377/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 2/5; 377/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 377/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 3/5; 377/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 4/5; 377/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 4/5; 377/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 5/5; 377/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 5/5; 377/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 378/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 1/5; 378/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 378/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 2/5; 378/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 378/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 3/5; 378/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 378/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 4/5; 378/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 378/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 5/5; 378/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 379/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 379/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 379/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 379/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 379/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 379/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 379/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 379/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 5/5; 379/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 379/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 1/5; 380/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 380/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 380/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 380/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 3/5; 380/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 380/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 380/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 380/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 380/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 380/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 381/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 1/5; 381/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 381/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 2/5; 381/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 381/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 3/5; 381/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 381/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 4/5; 381/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 5/5; 381/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 5/5; 381/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 1/5; 382/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 382/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 2/5; 382/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 382/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 3/5; 382/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 382/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 4/5; 382/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 382/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 5/5; 382/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 382/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 383/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 383/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 383/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 383/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 3/5; 383/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 383/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 383/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 383/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 383/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 383/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 384/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 1/5; 384/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 384/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 2/5; 384/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 384/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 3/5; 384/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 384/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 4/5; 384/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 384/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 5/5; 384/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 385/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 1/5; 385/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 385/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 2/5; 385/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 385/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 3/5; 385/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.2s\n",
      "[CV 4/5; 385/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 4/5; 385/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 385/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 5/5; 385/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 386/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 1/5; 386/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 386/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 2/5; 386/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 386/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 3/5; 386/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 386/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 4/5; 386/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 386/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 5/5; 386/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 387/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 1/5; 387/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 387/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 2/5; 387/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 3/5; 387/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 3/5; 387/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 387/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 4/5; 387/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 387/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 5/5; 387/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 388/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 388/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 388/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 388/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 388/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 388/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 388/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 388/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 388/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 388/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 389/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 389/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 2/5; 389/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 389/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 389/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 389/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 389/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 389/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 389/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 389/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 390/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 1/5; 390/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 390/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 2/5; 390/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 390/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 3/5; 390/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 390/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 4/5; 390/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 390/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 5/5; 390/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 391/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 391/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 391/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 391/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 391/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 391/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 391/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 391/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 391/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 391/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 392/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 392/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 392/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 392/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 392/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 392/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 392/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 392/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 392/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 392/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 393/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 1/5; 393/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 393/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 2/5; 393/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 393/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 3/5; 393/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 393/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 4/5; 393/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 393/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 5/5; 393/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 1/5; 394/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 1/5; 394/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 394/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 2/5; 394/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 394/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 3/5; 394/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 394/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 4/5; 394/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 394/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 5/5; 394/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 395/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 1/5; 395/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 395/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 2/5; 395/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 3/5; 395/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 3/5; 395/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 395/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 4/5; 395/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 395/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 5/5; 395/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 396/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 1/5; 396/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 396/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 2/5; 396/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 396/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 3/5; 396/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 396/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 4/5; 396/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 396/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 5/5; 396/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 397/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 397/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 397/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 397/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 397/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 397/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 397/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 397/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 397/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 397/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 398/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 398/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 398/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 398/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 398/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 398/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 398/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 398/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 398/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 398/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 399/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 1/5; 399/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 399/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 2/5; 399/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 399/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 3/5; 399/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 399/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 4/5; 399/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 399/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 5/5; 399/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 400/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 400/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 400/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 400/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 3/5; 400/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 400/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 400/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 400/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 400/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 400/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 401/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 401/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 401/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 401/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 3/5; 401/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 401/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 401/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 401/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 401/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 401/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 402/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 1/5; 402/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 402/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 2/5; 402/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 402/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 3/5; 402/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 402/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 4/5; 402/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 402/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 5/5; 402/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 403/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 1/5; 403/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 403/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 2/5; 403/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 403/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 3/5; 403/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 403/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 4/5; 403/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 403/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 5/5; 403/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 404/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 1/5; 404/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 404/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 2/5; 404/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 404/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 3/5; 404/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 404/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 4/5; 404/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 5/5; 404/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 5/5; 404/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 1/5; 405/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 1/5; 405/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 405/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 2/5; 405/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 405/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 3/5; 405/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 405/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 4/5; 405/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 405/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 5/5; 405/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 406/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 406/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 406/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 406/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 406/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 406/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 406/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 406/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 406/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 406/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 407/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 407/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 407/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 407/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 407/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 407/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 407/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 407/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 407/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 407/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 408/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 1/5; 408/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 408/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 2/5; 408/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 408/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 3/5; 408/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 408/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 4/5; 408/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 408/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 5/5; 408/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 409/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 409/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 409/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 409/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 409/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 409/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 409/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 409/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 409/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 409/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 410/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 410/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 410/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 410/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 410/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 410/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 410/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 410/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 410/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 410/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 411/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 1/5; 411/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 411/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 2/5; 411/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 411/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 3/5; 411/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 411/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 4/5; 411/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 411/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 5/5; 411/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 412/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 1/5; 412/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 2/5; 412/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 2/5; 412/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 412/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 3/5; 412/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 412/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 4/5; 412/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 412/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 5/5; 412/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 413/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 1/5; 413/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 413/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 2/5; 413/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 413/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 3/5; 413/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 413/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 4/5; 413/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 413/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 5/5; 413/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 414/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 1/5; 414/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 414/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 2/5; 414/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 414/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 3/5; 414/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 414/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 4/5; 414/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 414/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 5/5; 414/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 415/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 415/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 415/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 415/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 415/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 415/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 415/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 415/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 415/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 415/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 416/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 416/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 416/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 416/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 416/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 416/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 416/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 416/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 416/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 416/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 417/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 1/5; 417/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 417/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 2/5; 417/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 417/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 3/5; 417/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 417/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 4/5; 417/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 417/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 5/5; 417/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 418/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 418/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 418/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 418/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 418/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 418/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 418/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 418/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 418/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 418/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 419/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 419/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 419/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 419/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 419/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 419/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 419/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 419/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 419/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 419/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 420/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 1/5; 420/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 420/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 2/5; 420/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 420/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 3/5; 420/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 420/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 4/5; 420/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 420/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 5/5; 420/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 421/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 1/5; 421/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 421/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 2/5; 421/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 421/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 3/5; 421/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 421/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 4/5; 421/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 421/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 5/5; 421/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 422/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 1/5; 422/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 422/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 2/5; 422/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 422/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 3/5; 422/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 422/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 4/5; 422/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 422/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 5/5; 422/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 423/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 1/5; 423/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 423/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 2/5; 423/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 423/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 3/5; 423/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 423/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 4/5; 423/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 423/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 5/5; 423/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 424/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 424/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 424/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 424/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 3/5; 424/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 424/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 424/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 424/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 5/5; 424/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 424/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.2s\n",
      "[CV 1/5; 425/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 425/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 425/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 425/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 425/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 425/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 4/5; 425/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 425/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 425/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 425/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 426/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 1/5; 426/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 426/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 2/5; 426/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 426/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 3/5; 426/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 426/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 4/5; 426/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 426/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 5/5; 426/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 427/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 427/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 427/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 427/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 427/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 427/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 427/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 427/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 427/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 427/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 428/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 428/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 428/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 428/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 428/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 428/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 428/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 428/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 5/5; 428/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 428/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 1/5; 429/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 1/5; 429/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 429/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 2/5; 429/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 429/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 3/5; 429/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 429/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 4/5; 429/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 429/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 5/5; 429/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 430/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 1/5; 430/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 430/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 2/5; 430/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 430/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 3/5; 430/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 430/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 4/5; 430/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 430/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 5/5; 430/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 431/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 1/5; 431/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 431/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 2/5; 431/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 431/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 3/5; 431/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 431/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 4/5; 431/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 431/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 5/5; 431/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 432/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 1/5; 432/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 432/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 2/5; 432/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 432/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 3/5; 432/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 4/5; 432/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 4/5; 432/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 5/5; 432/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 5/5; 432/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 433/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 433/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 433/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 433/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 433/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 433/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 433/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 433/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 433/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 433/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 434/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 434/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 434/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 434/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 3/5; 434/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 434/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 434/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 434/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 434/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 434/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 435/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 1/5; 435/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 435/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 2/5; 435/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 435/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 3/5; 435/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 435/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 4/5; 435/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 435/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 5/5; 435/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 436/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 436/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 436/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 436/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 436/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 436/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 436/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 436/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 436/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 436/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 437/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 437/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 437/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 437/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 437/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 437/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 437/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 437/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 437/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 437/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 438/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 1/5; 438/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 438/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 2/5; 438/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 438/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 3/5; 438/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 438/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 4/5; 438/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 438/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 5/5; 438/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 439/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 1/5; 439/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 439/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 2/5; 439/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 439/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 3/5; 439/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 439/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 4/5; 439/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 439/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 5/5; 439/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 440/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 1/5; 440/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 440/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 2/5; 440/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 440/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 3/5; 440/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 440/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 4/5; 440/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 440/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 5/5; 440/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 441/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 1/5; 441/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 441/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 2/5; 441/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 441/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 3/5; 441/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 441/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 4/5; 441/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 441/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 5/5; 441/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 442/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 442/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 442/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 442/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 3/5; 442/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 442/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 4/5; 442/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 442/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 442/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 442/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.2s\n",
      "[CV 1/5; 443/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 443/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 443/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 443/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 443/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 443/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 443/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 443/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 443/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 443/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 444/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 1/5; 444/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 444/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 2/5; 444/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 444/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 3/5; 444/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 444/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 4/5; 444/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 444/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 5/5; 444/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 445/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 445/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 445/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 445/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 445/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 445/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 445/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 445/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 445/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 445/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 446/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 446/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 446/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 446/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 446/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 446/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 446/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 446/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 446/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 446/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 447/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 1/5; 447/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 447/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 2/5; 447/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 447/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 3/5; 447/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 447/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 4/5; 447/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 447/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 5/5; 447/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 448/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 1/5; 448/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 448/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 2/5; 448/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 448/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 3/5; 448/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 448/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 4/5; 448/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 448/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 5/5; 448/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 449/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 1/5; 449/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 449/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 2/5; 449/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 449/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 3/5; 449/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 449/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 4/5; 449/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 449/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 5/5; 449/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 450/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 1/5; 450/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 450/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 2/5; 450/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 450/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 3/5; 450/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 450/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 4/5; 450/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 450/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 5/5; 450/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 451/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 451/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 451/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 451/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 451/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 451/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 451/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 451/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 451/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 451/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 452/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 452/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 452/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 452/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 452/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 452/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 452/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 452/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 452/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 452/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 453/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 1/5; 453/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 453/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 2/5; 453/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 453/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 3/5; 453/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 453/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 4/5; 453/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 453/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 5/5; 453/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 454/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 454/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 454/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 454/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 454/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 454/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 454/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 454/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 454/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 454/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 455/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 455/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 455/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 455/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 455/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 455/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 455/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 455/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 455/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 455/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 456/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 1/5; 456/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 456/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 2/5; 456/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 456/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 3/5; 456/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 456/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 4/5; 456/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 456/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 5/5; 456/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 457/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 1/5; 457/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 457/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 2/5; 457/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 457/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 3/5; 457/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 457/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 4/5; 457/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 457/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 5/5; 457/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 458/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 1/5; 458/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 458/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 2/5; 458/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 458/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 3/5; 458/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 458/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 4/5; 458/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 458/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 5/5; 458/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 459/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 1/5; 459/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 459/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 2/5; 459/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 459/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 3/5; 459/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 459/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 4/5; 459/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 459/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 5/5; 459/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 460/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 460/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 460/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 460/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 3/5; 460/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 460/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 460/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 460/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 460/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 460/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 461/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 461/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 461/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 461/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 3/5; 461/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 461/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 4/5; 461/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 461/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 5/5; 461/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 461/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 1/5; 462/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 1/5; 462/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 462/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 2/5; 462/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 462/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 3/5; 462/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 462/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 4/5; 462/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 462/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 5/5; 462/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 463/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 463/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 463/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 463/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 463/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 463/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 463/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 463/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 463/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 463/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 464/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 464/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 464/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 464/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.2s\n",
      "[CV 3/5; 464/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 464/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 464/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 464/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 464/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 464/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 465/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 1/5; 465/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 465/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 2/5; 465/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 465/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 3/5; 465/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 465/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 4/5; 465/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 465/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 5/5; 465/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 466/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 1/5; 466/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 466/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 2/5; 466/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 466/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 3/5; 466/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 466/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 4/5; 466/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 466/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 5/5; 466/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 467/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 1/5; 467/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 467/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 2/5; 467/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 467/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 3/5; 467/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 4/5; 467/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 4/5; 467/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 5/5; 467/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 5/5; 467/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 468/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 1/5; 468/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 468/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 2/5; 468/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 468/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 3/5; 468/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 468/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 4/5; 468/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 468/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 5/5; 468/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 469/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 469/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 469/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 469/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 469/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 469/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 469/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 469/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 469/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 469/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 470/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 470/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 470/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 470/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 470/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 470/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 470/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 470/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 470/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 470/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 471/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 1/5; 471/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 471/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 2/5; 471/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 471/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 3/5; 471/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 471/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 4/5; 471/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 471/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 5/5; 471/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 472/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 472/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 472/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 472/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 3/5; 472/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 472/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 472/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 472/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 472/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 472/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 473/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 473/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 473/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 473/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 473/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 473/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 473/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 473/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 473/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 473/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 474/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 1/5; 474/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 2/5; 474/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 2/5; 474/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 3/5; 474/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 3/5; 474/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 4/5; 474/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 4/5; 474/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 474/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 5/5; 474/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 475/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 1/5; 475/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 2/5; 475/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 2/5; 475/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.2s\n",
      "[CV 3/5; 475/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 3/5; 475/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.2s\n",
      "[CV 4/5; 475/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 4/5; 475/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 5/5; 475/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 5/5; 475/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 1/5; 476/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 1/5; 476/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.2s\n",
      "[CV 2/5; 476/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 2/5; 476/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.3s\n",
      "[CV 3/5; 476/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 3/5; 476/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.2s\n",
      "[CV 4/5; 476/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 4/5; 476/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.2s\n",
      "[CV 5/5; 476/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 5/5; 476/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 1/5; 477/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 1/5; 477/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 2/5; 477/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 2/5; 477/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.2s\n",
      "[CV 3/5; 477/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 3/5; 477/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.2s\n",
      "[CV 4/5; 477/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 4/5; 477/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 5/5; 477/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 5/5; 477/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.2s\n",
      "[CV 1/5; 478/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 478/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 2/5; 478/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 478/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.2s\n",
      "[CV 3/5; 478/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 478/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.2s\n",
      "[CV 4/5; 478/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 478/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 5/5; 478/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 478/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.2s\n",
      "[CV 1/5; 479/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 479/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.2s\n",
      "[CV 2/5; 479/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 479/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.2s\n",
      "[CV 3/5; 479/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 479/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 4/5; 479/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 479/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 5/5; 479/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 479/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 1/5; 480/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 1/5; 480/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 2/5; 480/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 2/5; 480/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.2s\n",
      "[CV 3/5; 480/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 3/5; 480/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 4/5; 480/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 4/5; 480/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.2s\n",
      "[CV 5/5; 480/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 5/5; 480/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.2s\n",
      "[CV 1/5; 481/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 481/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 2/5; 481/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 481/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.2s\n",
      "[CV 3/5; 481/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 481/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.2s\n",
      "[CV 4/5; 481/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 481/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 5/5; 481/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 481/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 1/5; 482/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 482/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.2s\n",
      "[CV 2/5; 482/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 482/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.2s\n",
      "[CV 3/5; 482/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 482/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.3s\n",
      "[CV 4/5; 482/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 482/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 5/5; 482/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 482/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.2s\n",
      "[CV 1/5; 483/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 1/5; 483/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.2s\n",
      "[CV 2/5; 483/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 2/5; 483/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 3/5; 483/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 3/5; 483/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 4/5; 483/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 4/5; 483/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 5/5; 483/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 5/5; 483/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.2s\n",
      "[CV 1/5; 484/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 1/5; 484/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 2/5; 484/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 2/5; 484/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 484/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 3/5; 484/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 484/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 4/5; 484/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 484/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 5/5; 484/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 1/5; 485/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 1/5; 485/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 2/5; 485/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 2/5; 485/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 485/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 3/5; 485/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 485/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 4/5; 485/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 485/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 5/5; 485/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 486/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 1/5; 486/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 486/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 2/5; 486/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 486/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 3/5; 486/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 486/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 4/5; 486/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 486/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 5/5; 486/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 487/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 487/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 487/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 487/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 487/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 487/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 487/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 487/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 487/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 487/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 488/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 488/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 2/5; 488/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 488/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 488/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 488/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 488/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 488/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 488/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 488/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 489/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 1/5; 489/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 489/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 2/5; 489/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 489/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 3/5; 489/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 489/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 4/5; 489/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 5/5; 489/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 5/5; 489/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.2s\n",
      "[CV 1/5; 490/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 490/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 2/5; 490/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 490/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 490/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 490/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 490/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 490/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 490/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 490/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 1/5; 491/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 491/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 491/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 491/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 491/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 491/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 491/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 491/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 491/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 491/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 492/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 1/5; 492/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 2/5; 492/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 2/5; 492/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 492/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 3/5; 492/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 492/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 4/5; 492/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 492/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 5/5; 492/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 493/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 1/5; 493/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 493/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 2/5; 493/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 3/5; 493/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 3/5; 493/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 4/5; 493/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 4/5; 493/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 493/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 5/5; 493/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 494/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 1/5; 494/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 494/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 2/5; 494/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 494/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 3/5; 494/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 4/5; 494/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 4/5; 494/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 5/5; 494/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 5/5; 494/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 495/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 1/5; 495/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 495/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 2/5; 495/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 495/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 3/5; 495/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 495/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 4/5; 495/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 5/5; 495/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 5/5; 495/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.2s\n",
      "[CV 1/5; 496/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 496/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.2s\n",
      "[CV 2/5; 496/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 496/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 3/5; 496/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 496/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 4/5; 496/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 496/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 496/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 496/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 497/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 497/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 2/5; 497/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 497/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.2s\n",
      "[CV 3/5; 497/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 497/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.3s\n",
      "[CV 4/5; 497/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 497/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 5/5; 497/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 497/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 1/5; 498/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 1/5; 498/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.3s\n",
      "[CV 2/5; 498/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 2/5; 498/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 498/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 3/5; 498/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 4/5; 498/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 4/5; 498/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 5/5; 498/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 5/5; 498/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.3s\n",
      "[CV 1/5; 499/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 499/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 2/5; 499/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 499/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 3/5; 499/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 499/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.2s\n",
      "[CV 4/5; 499/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 499/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.2s\n",
      "[CV 5/5; 499/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 499/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.2s\n",
      "[CV 1/5; 500/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 500/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.2s\n",
      "[CV 2/5; 500/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 500/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.2s\n",
      "[CV 3/5; 500/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 500/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.2s\n",
      "[CV 4/5; 500/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 500/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.2s\n",
      "[CV 5/5; 500/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 500/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.2s\n",
      "[CV 1/5; 501/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 1/5; 501/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.2s\n",
      "[CV 2/5; 501/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 2/5; 501/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.2s\n",
      "[CV 3/5; 501/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 3/5; 501/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.2s\n",
      "[CV 4/5; 501/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 4/5; 501/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.2s\n",
      "[CV 5/5; 501/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 5/5; 501/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.3s\n",
      "[CV 1/5; 502/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 1/5; 502/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.2s\n",
      "[CV 2/5; 502/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 2/5; 502/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 502/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 3/5; 502/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 502/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 4/5; 502/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 502/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 5/5; 502/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 503/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 1/5; 503/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 503/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 2/5; 503/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 503/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 3/5; 503/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.2s\n",
      "[CV 4/5; 503/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 4/5; 503/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 503/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 5/5; 503/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 504/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 1/5; 504/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 504/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 2/5; 504/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 504/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 3/5; 504/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 504/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 4/5; 504/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 504/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 5/5; 504/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 1/5; 505/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 505/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 2/5; 505/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 505/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 505/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 505/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 505/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 505/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 505/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 505/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.2s\n",
      "[CV 1/5; 506/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 506/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 2/5; 506/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 506/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 506/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 506/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 506/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 506/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 506/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 506/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.2s\n",
      "[CV 1/5; 507/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 1/5; 507/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.2s\n",
      "[CV 2/5; 507/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 2/5; 507/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.2s\n",
      "[CV 3/5; 507/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 3/5; 507/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.2s\n",
      "[CV 4/5; 507/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 4/5; 507/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 5/5; 507/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 5/5; 507/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 1/5; 508/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 508/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 508/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 508/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 508/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 508/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 508/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 508/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 508/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 508/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 509/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 509/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 509/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 509/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 509/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 509/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 509/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 509/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 509/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 509/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 510/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 1/5; 510/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 510/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 2/5; 510/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 510/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 3/5; 510/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 510/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 4/5; 510/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 510/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 5/5; 510/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 511/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 1/5; 511/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 511/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 2/5; 511/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 511/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 3/5; 511/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 511/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 4/5; 511/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 511/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 5/5; 511/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 512/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 1/5; 512/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 512/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 2/5; 512/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 3/5; 512/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 3/5; 512/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 512/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 4/5; 512/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 512/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 5/5; 512/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 513/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 1/5; 513/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 513/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 2/5; 513/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 513/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 3/5; 513/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 513/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 4/5; 513/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 513/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 5/5; 513/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 514/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 514/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 514/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 514/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 514/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 514/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 514/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 514/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 514/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 514/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 515/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 515/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 515/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 515/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 515/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 515/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 515/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 515/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 515/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 515/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 516/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 1/5; 516/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 516/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 2/5; 516/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 516/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 3/5; 516/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 516/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 4/5; 516/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 516/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 5/5; 516/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 517/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 517/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 517/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 517/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 517/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 517/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 4/5; 517/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 517/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 517/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 517/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 518/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 518/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 518/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 518/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 518/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 518/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 518/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 518/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 518/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 518/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 519/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 1/5; 519/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 519/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 2/5; 519/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 519/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 3/5; 519/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 519/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 4/5; 519/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 519/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 5/5; 519/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 520/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 1/5; 520/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 520/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 2/5; 520/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 520/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 3/5; 520/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 520/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 4/5; 520/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 520/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 5/5; 520/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 521/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 1/5; 521/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 521/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 2/5; 521/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 521/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 3/5; 521/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 521/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 4/5; 521/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 521/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 5/5; 521/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 522/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 1/5; 522/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 522/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 2/5; 522/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 522/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 3/5; 522/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 522/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 4/5; 522/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 5/5; 522/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 5/5; 522/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 523/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 523/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 523/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 523/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 523/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 523/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 523/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 523/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 523/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 523/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 524/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 524/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 524/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 524/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 524/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 524/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 524/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 524/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 524/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 524/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 525/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 1/5; 525/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 525/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 2/5; 525/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 525/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 3/5; 525/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 525/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 4/5; 525/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 525/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 5/5; 525/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 526/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 526/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 526/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 526/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 526/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 526/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 526/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 526/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 526/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 526/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 527/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 527/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 527/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 527/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 527/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 527/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 527/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 527/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 527/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 527/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 528/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 1/5; 528/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 2/5; 528/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 2/5; 528/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 528/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 3/5; 528/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 528/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 4/5; 528/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 528/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 5/5; 528/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 529/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 1/5; 529/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 529/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 2/5; 529/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 529/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 3/5; 529/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 529/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 4/5; 529/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 5/5; 529/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 5/5; 529/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 1/5; 530/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 1/5; 530/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 530/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 2/5; 530/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 530/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 3/5; 530/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 530/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 4/5; 530/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 530/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 5/5; 530/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 531/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 1/5; 531/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 531/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 2/5; 531/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 531/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 3/5; 531/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 531/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 4/5; 531/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 531/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 5/5; 531/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 532/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 532/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 532/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 532/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 532/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 532/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 532/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 532/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 532/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 532/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 533/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 533/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 2/5; 533/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 533/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 533/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 533/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 533/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 533/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 533/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 533/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 534/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 1/5; 534/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 534/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 2/5; 534/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 534/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 3/5; 534/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 4/5; 534/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 4/5; 534/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 534/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 5/5; 534/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 535/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 535/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 535/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 535/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 535/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 535/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 535/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 535/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 535/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 535/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 536/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 536/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 536/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 536/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 536/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 536/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 536/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 536/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 536/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 536/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 537/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 1/5; 537/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 2/5; 537/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 2/5; 537/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 537/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 3/5; 537/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 537/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 4/5; 537/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 537/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 5/5; 537/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 538/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 1/5; 538/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 2/5; 538/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 2/5; 538/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 538/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 3/5; 538/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 538/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 4/5; 538/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 538/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 5/5; 538/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 539/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 1/5; 539/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 539/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 2/5; 539/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 539/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 3/5; 539/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 539/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 4/5; 539/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 539/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 5/5; 539/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 540/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 1/5; 540/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 540/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 2/5; 540/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 540/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 3/5; 540/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 540/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 4/5; 540/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 540/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 5/5; 540/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 541/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 541/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 541/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 541/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 541/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 541/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 541/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 541/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 541/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 541/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 542/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 542/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 542/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 542/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 542/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 542/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 542/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 542/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 542/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 542/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 543/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 1/5; 543/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 543/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 2/5; 543/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 3/5; 543/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 3/5; 543/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 543/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 4/5; 543/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.2s\n",
      "[CV 5/5; 543/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 5/5; 543/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 544/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 544/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 544/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 544/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 3/5; 544/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 544/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 4/5; 544/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 544/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 544/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 544/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 545/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 545/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 545/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 545/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 545/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 545/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 545/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 545/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 545/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 545/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 546/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 1/5; 546/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 546/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 2/5; 546/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 546/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 3/5; 546/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 546/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 4/5; 546/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 546/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 5/5; 546/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 547/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 1/5; 547/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 547/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 2/5; 547/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 547/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 3/5; 547/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 547/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 4/5; 547/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 547/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 5/5; 547/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 548/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 1/5; 548/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 2/5; 548/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 2/5; 548/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 548/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 3/5; 548/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 548/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 4/5; 548/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 548/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 5/5; 548/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 1/5; 549/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 1/5; 549/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 2/5; 549/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 2/5; 549/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 549/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 3/5; 549/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 549/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 4/5; 549/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 5/5; 549/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 5/5; 549/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.2s\n",
      "[CV 1/5; 550/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 550/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.2s\n",
      "[CV 2/5; 550/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 550/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 3/5; 550/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 550/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 4/5; 550/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 550/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.3s\n",
      "[CV 5/5; 550/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 550/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 1/5; 551/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 551/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 2/5; 551/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 551/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 3/5; 551/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 551/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 551/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 551/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 551/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 551/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 552/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 1/5; 552/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 552/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 2/5; 552/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 552/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 3/5; 552/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 552/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 4/5; 552/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 5/5; 552/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 5/5; 552/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 553/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 553/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 553/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 553/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 553/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 553/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 553/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 553/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 553/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 553/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.3s\n",
      "[CV 1/5; 554/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 554/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 2/5; 554/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 554/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 554/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 554/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 554/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 554/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.2s\n",
      "[CV 5/5; 554/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 554/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 1/5; 555/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 1/5; 555/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 555/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 2/5; 555/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 555/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 3/5; 555/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 4/5; 555/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 4/5; 555/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.3s\n",
      "[CV 5/5; 555/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 5/5; 555/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 1/5; 556/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 1/5; 556/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 2/5; 556/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 2/5; 556/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 556/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 3/5; 556/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.2s\n",
      "[CV 4/5; 556/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 4/5; 556/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 5/5; 556/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 5/5; 556/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.2s\n",
      "[CV 1/5; 557/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 1/5; 557/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 2/5; 557/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 2/5; 557/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.2s\n",
      "[CV 3/5; 557/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 3/5; 557/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 557/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 4/5; 557/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 557/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 5/5; 557/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 1/5; 558/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 1/5; 558/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.3s\n",
      "[CV 2/5; 558/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 2/5; 558/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 558/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 3/5; 558/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 4/5; 558/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 4/5; 558/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 558/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
      "[CV 5/5; 558/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 559/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 559/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 559/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 559/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.2s\n",
      "[CV 3/5; 559/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 559/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.2s\n",
      "[CV 4/5; 559/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 559/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.2s\n",
      "[CV 5/5; 559/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 559/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 1/5; 560/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 560/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 560/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 560/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 3/5; 560/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 560/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 4/5; 560/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 560/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 560/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 560/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 561/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 1/5; 561/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 561/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 2/5; 561/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 561/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 3/5; 561/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 4/5; 561/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 4/5; 561/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.2s\n",
      "[CV 5/5; 561/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 5/5; 561/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 562/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 562/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 562/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 562/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 562/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 562/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 4/5; 562/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 562/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 562/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 562/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 563/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 563/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 563/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 563/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 563/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 563/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 563/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 563/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 563/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 563/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 1/5; 564/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 1/5; 564/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 564/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 2/5; 564/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 564/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 3/5; 564/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 564/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 4/5; 564/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 564/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 5/5; 564/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 565/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 1/5; 565/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 2/5; 565/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 2/5; 565/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 565/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 3/5; 565/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 565/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 4/5; 565/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 565/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 5/5; 565/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 566/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 1/5; 566/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 566/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 2/5; 566/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 3/5; 566/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 3/5; 566/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 566/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 4/5; 566/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 566/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 5/5; 566/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 567/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 1/5; 567/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 2/5; 567/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 2/5; 567/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.2s\n",
      "[CV 3/5; 567/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 3/5; 567/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 4/5; 567/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 4/5; 567/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.2s\n",
      "[CV 5/5; 567/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 5/5; 567/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 568/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 568/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 568/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 568/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 568/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 568/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 568/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 568/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.3s\n",
      "[CV 5/5; 568/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 568/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 569/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 569/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 569/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 569/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 569/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 569/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 569/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 569/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 5/5; 569/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 569/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 570/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 1/5; 570/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 570/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 2/5; 570/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 570/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 3/5; 570/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 570/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 4/5; 570/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 570/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
      "[CV 5/5; 570/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 1/5; 571/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 571/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 571/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 571/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 571/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 571/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 571/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 571/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 5/5; 571/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 571/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 1/5; 572/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 572/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 572/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 572/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 572/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 572/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 4/5; 572/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 572/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 5/5; 572/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 572/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 573/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 1/5; 573/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 573/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 2/5; 573/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 3/5; 573/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 3/5; 573/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 573/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 4/5; 573/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 573/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
      "[CV 5/5; 573/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 574/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 1/5; 574/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 574/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 2/5; 574/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 574/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 3/5; 574/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 4/5; 574/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 4/5; 574/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 574/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
      "[CV 5/5; 574/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 575/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 1/5; 575/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 575/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 2/5; 575/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 575/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 3/5; 575/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 575/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 4/5; 575/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 5/5; 575/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
      "[CV 5/5; 575/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 576/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 1/5; 576/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 576/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 2/5; 576/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 3/5; 576/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 3/5; 576/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 576/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 4/5; 576/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 576/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
      "[CV 5/5; 576/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 1/5; 577/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 577/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 577/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 577/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 3/5; 577/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 3/5; 577/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 577/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 4/5; 577/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 577/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 5/5; 577/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 578/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 1/5; 578/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.3s\n",
      "[CV 2/5; 578/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 2/5; 578/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 3/5; 578/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 3/5; 578/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 578/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 4/5; 578/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 578/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
      "[CV 5/5; 578/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 579/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 1/5; 579/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 2/5; 579/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 2/5; 579/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 579/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 3/5; 579/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 579/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 4/5; 579/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 5/5; 579/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
      "[CV 5/5; 579/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 1/5; 580/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 1/5; 580/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 2/5; 580/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 2/5; 580/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 3/5; 580/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 3/5; 580/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 4/5; 580/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 4/5; 580/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 580/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
      "[CV 5/5; 580/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 581/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 1/5; 581/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 2/5; 581/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 2/5; 581/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 3/5; 581/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 3/5; 581/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 581/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 4/5; 581/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 5/5; 581/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
      "[CV 5/5; 581/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 582/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 1/5; 582/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 2/5; 582/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 2/5; 582/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 3/5; 582/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 3/5; 582/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.0s\n",
      "[CV 4/5; 582/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 4/5; 582/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.1s\n",
      "[CV 5/5; 582/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
      "[CV 5/5; 582/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=nan total time=   0.3s\n",
      "[CV 1/5; 583/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 1/5; 583/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 2/5; 583/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 2/5; 583/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 3/5; 583/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 3/5; 583/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.1s\n",
      "[CV 4/5; 583/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 4/5; 583/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 5/5; 583/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
      "[CV 5/5; 583/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=nan total time=   0.0s\n",
      "[CV 1/5; 584/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 1/5; 584/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 2/5; 584/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 2/5; 584/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 3/5; 584/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 3/5; 584/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 4/5; 584/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 4/5; 584/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.1s\n",
      "[CV 5/5; 584/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
      "[CV 5/5; 584/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=nan total time=   0.0s\n",
      "[CV 1/5; 585/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Hi\\Desktop\\VS_Code_conda\\ML Assignments1\\Neural Networks\\Fireforests_ANN.ipynb Cell 26\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Hi/Desktop/VS_Code_conda/ML%20Assignments1/Neural%20Networks/Fireforests_ANN.ipynb#X63sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m#Build and fit the GridsearchCV\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Hi/Desktop/VS_Code_conda/ML%20Assignments1/Neural%20Networks/Fireforests_ANN.ipynb#X63sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m grid\u001b[39m=\u001b[39mGridSearchCV(estimator\u001b[39m=\u001b[39mmodel,param_grid\u001b[39m=\u001b[39mparams_grid,verbose\u001b[39m=\u001b[39m\u001b[39m11\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Hi/Desktop/VS_Code_conda/ML%20Assignments1/Neural%20Networks/Fireforests_ANN.ipynb#X63sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m grid\u001b[39m.\u001b[39;49mfit(X,Y)\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    885\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    886\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    887\u001b[0m     )\n\u001b[0;32m    889\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 891\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    893\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    894\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    895\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1392\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1391\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1392\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    831\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    832\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    833\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    834\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    835\u001b[0m         )\n\u001b[0;32m    836\u001b[0m     )\n\u001b[1;32m--> 838\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    839\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    840\u001b[0m         clone(base_estimator),\n\u001b[0;32m    841\u001b[0m         X,\n\u001b[0;32m    842\u001b[0m         y,\n\u001b[0;32m    843\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    844\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    845\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    846\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    847\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    848\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    849\u001b[0m     )\n\u001b[0;32m    850\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    851\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    852\u001b[0m     )\n\u001b[0;32m    853\u001b[0m )\n\u001b[0;32m    855\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    856\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    857\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    858\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    859\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    860\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1051\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1049\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1051\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1052\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1054\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1055\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1056\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1057\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:864\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    863\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 864\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    865\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:782\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    780\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    781\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 782\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    783\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    785\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:263\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    260\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 263\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    264\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:263\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    260\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 263\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    264\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    215\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> 216\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    678\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    679\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 680\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    682\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    683\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    684\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py:155\u001b[0m, in \u001b[0;36mBaseWrapper.fit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    152\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuild_fn(\n\u001b[0;32m    153\u001b[0m       \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilter_sk_params(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuild_fn\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m))\n\u001b[0;32m    154\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 155\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuild_fn(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilter_sk_params(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuild_fn))\n\u001b[0;32m    157\u001b[0m \u001b[39mif\u001b[39;00m (losses\u001b[39m.\u001b[39mis_categorical_crossentropy(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mloss) \u001b[39mand\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[39mlen\u001b[39m(y\u001b[39m.\u001b[39mshape) \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m):\n\u001b[0;32m    159\u001b[0m   y \u001b[39m=\u001b[39m to_categorical(y)\n",
      "\u001b[1;32mc:\\Users\\Hi\\Desktop\\VS_Code_conda\\ML Assignments1\\Neural Networks\\Fireforests_ANN.ipynb Cell 26\u001b[0m in \u001b[0;36mcreate_model\u001b[1;34m(learning_rate, dropout_rate, activation_function, init, neuron1, neuron2)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Hi/Desktop/VS_Code_conda/ML%20Assignments1/Neural%20Networks/Fireforests_ANN.ipynb#X63sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m model\u001b[39m.\u001b[39madd(Dense(\u001b[39m1\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Hi/Desktop/VS_Code_conda/ML%20Assignments1/Neural%20Networks/Fireforests_ANN.ipynb#X63sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m adam\u001b[39m=\u001b[39m Adam(learning_rate\u001b[39m=\u001b[39mlearning_rate)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Hi/Desktop/VS_Code_conda/ML%20Assignments1/Neural%20Networks/Fireforests_ANN.ipynb#X63sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m model\u001b[39m.\u001b[39;49mcompile(loss\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrmsprop\u001b[39;49m\u001b[39m'\u001b[39;49m,optimizer\u001b[39m=\u001b[39;49madam,metrics\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39maccuracy\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mmse\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Hi/Desktop/VS_Code_conda/ML%20Assignments1/Neural%20Networks/Fireforests_ANN.ipynb#X63sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:642\u001b[0m, in \u001b[0;36mModel.compile\u001b[1;34m(self, optimizer, loss, metrics, loss_weights, weighted_metrics, run_eagerly, steps_per_execution, jit_compile, **kwargs)\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_eagerly \u001b[39m=\u001b[39m run_eagerly\n\u001b[0;32m    641\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_optimizer(optimizer)\n\u001b[1;32m--> 642\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompiled_loss \u001b[39m=\u001b[39m compile_utils\u001b[39m.\u001b[39;49mLossesContainer(\n\u001b[0;32m    643\u001b[0m     loss, loss_weights, output_names\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput_names)\n\u001b[0;32m    644\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompiled_metrics \u001b[39m=\u001b[39m compile_utils\u001b[39m.\u001b[39mMetricsContainer(\n\u001b[0;32m    645\u001b[0m     metrics, weighted_metrics, output_names\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_names,\n\u001b[0;32m    646\u001b[0m     from_serialized\u001b[39m=\u001b[39mfrom_serialized)\n\u001b[0;32m    648\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_configure_steps_per_execution(steps_per_execution \u001b[39mor\u001b[39;00m \u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py:113\u001b[0m, in \u001b[0;36mLossesContainer.__init__\u001b[1;34m(self, losses, loss_weights, output_names)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_loss_weights \u001b[39m=\u001b[39m loss_weights\n\u001b[0;32m    112\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_per_output_metrics \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m  \u001b[39m# Per-output losses become metrics.\u001b[39;00m\n\u001b[1;32m--> 113\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_loss_metric \u001b[39m=\u001b[39m metrics_mod\u001b[39m.\u001b[39;49mMean(name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mloss\u001b[39;49m\u001b[39m'\u001b[39;49m)  \u001b[39m# Total loss.\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_built \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\lib\\site-packages\\keras\\dtensor\\utils.py:141\u001b[0m, in \u001b[0;36minject_mesh.<locals>._wrap_function\u001b[1;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[39mif\u001b[39;00m mesh \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    140\u001b[0m   instance\u001b[39m.\u001b[39m_mesh \u001b[39m=\u001b[39m mesh  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 141\u001b[0m init_method(instance, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\lib\\site-packages\\keras\\metrics\\base_metric.py:578\u001b[0m, in \u001b[0;36mMean.__init__\u001b[1;34m(self, name, dtype)\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[39m@dtensor_utils\u001b[39m\u001b[39m.\u001b[39minject_mesh\n\u001b[0;32m    577\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 578\u001b[0m   \u001b[39msuper\u001b[39;49m(Mean, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[0;32m    579\u001b[0m       reduction\u001b[39m=\u001b[39;49mmetrics_utils\u001b[39m.\u001b[39;49mReduction\u001b[39m.\u001b[39;49mWEIGHTED_MEAN, name\u001b[39m=\u001b[39;49mname, dtype\u001b[39m=\u001b[39;49mdtype)\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\lib\\site-packages\\keras\\metrics\\base_metric.py:417\u001b[0m, in \u001b[0;36mReduce.__init__\u001b[1;34m(self, reduction, name, dtype)\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_weight(\n\u001b[0;32m    414\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtotal\u001b[39m\u001b[39m'\u001b[39m, initializer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    415\u001b[0m \u001b[39mif\u001b[39;00m reduction \u001b[39min\u001b[39;00m [metrics_utils\u001b[39m.\u001b[39mReduction\u001b[39m.\u001b[39mSUM_OVER_BATCH_SIZE,\n\u001b[0;32m    416\u001b[0m                  metrics_utils\u001b[39m.\u001b[39mReduction\u001b[39m.\u001b[39mWEIGHTED_MEAN]:\n\u001b[1;32m--> 417\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcount \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_weight(\n\u001b[0;32m    418\u001b[0m       \u001b[39m'\u001b[39;49m\u001b[39mcount\u001b[39;49m\u001b[39m'\u001b[39;49m, initializer\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mzeros\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\lib\\site-packages\\keras\\metrics\\base_metric.py:351\u001b[0m, in \u001b[0;36mMetric.add_weight\u001b[1;34m(self, name, shape, aggregation, synchronization, initializer, dtype)\u001b[0m\n\u001b[0;32m    348\u001b[0m   additional_kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m    350\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39minit_scope():\n\u001b[1;32m--> 351\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m(Metric, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39madd_weight(\n\u001b[0;32m    352\u001b[0m       name\u001b[39m=\u001b[39mname,\n\u001b[0;32m    353\u001b[0m       shape\u001b[39m=\u001b[39mshape,\n\u001b[0;32m    354\u001b[0m       dtype\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dtype \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m dtype,\n\u001b[0;32m    355\u001b[0m       trainable\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    356\u001b[0m       initializer\u001b[39m=\u001b[39minitializer,\n\u001b[0;32m    357\u001b[0m       collections\u001b[39m=\u001b[39m[],\n\u001b[0;32m    358\u001b[0m       synchronization\u001b[39m=\u001b[39msynchronization,\n\u001b[0;32m    359\u001b[0m       aggregation\u001b[39m=\u001b[39maggregation,\n\u001b[0;32m    360\u001b[0m       \u001b[39m*\u001b[39m\u001b[39m*\u001b[39madditional_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py:665\u001b[0m, in \u001b[0;36mLayer.add_weight\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[0;32m    662\u001b[0m \u001b[39mif\u001b[39;00m layout:\n\u001b[0;32m    663\u001b[0m   getter \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39mpartial(getter, layout\u001b[39m=\u001b[39mlayout)\n\u001b[1;32m--> 665\u001b[0m variable \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_add_variable_with_custom_getter(\n\u001b[0;32m    666\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m    667\u001b[0m     shape\u001b[39m=\u001b[39;49mshape,\n\u001b[0;32m    668\u001b[0m     \u001b[39m# TODO(allenl): a `make_variable` equivalent should be added as a\u001b[39;49;00m\n\u001b[0;32m    669\u001b[0m     \u001b[39m# `Trackable` method.\u001b[39;49;00m\n\u001b[0;32m    670\u001b[0m     getter\u001b[39m=\u001b[39;49mgetter,\n\u001b[0;32m    671\u001b[0m     \u001b[39m# Manage errors in Layer rather than Trackable.\u001b[39;49;00m\n\u001b[0;32m    672\u001b[0m     overwrite\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    673\u001b[0m     initializer\u001b[39m=\u001b[39;49minitializer,\n\u001b[0;32m    674\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    675\u001b[0m     constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[0;32m    676\u001b[0m     trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[0;32m    677\u001b[0m     use_resource\u001b[39m=\u001b[39;49muse_resource,\n\u001b[0;32m    678\u001b[0m     collections\u001b[39m=\u001b[39;49mcollections_arg,\n\u001b[0;32m    679\u001b[0m     synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[0;32m    680\u001b[0m     aggregation\u001b[39m=\u001b[39;49maggregation,\n\u001b[0;32m    681\u001b[0m     caching_device\u001b[39m=\u001b[39;49mcaching_device)\n\u001b[0;32m    682\u001b[0m \u001b[39mif\u001b[39;00m regularizer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    683\u001b[0m   \u001b[39m# TODO(fchollet): in the future, this should be handled at the\u001b[39;00m\n\u001b[0;32m    684\u001b[0m   \u001b[39m# level of variable creation, and weight regularization losses\u001b[39;00m\n\u001b[0;32m    685\u001b[0m   \u001b[39m# should be variable attributes.\u001b[39;00m\n\u001b[0;32m    686\u001b[0m   name_in_scope \u001b[39m=\u001b[39m variable\u001b[39m.\u001b[39mname[:variable\u001b[39m.\u001b[39mname\u001b[39m.\u001b[39mfind(\u001b[39m'\u001b[39m\u001b[39m:\u001b[39m\u001b[39m'\u001b[39m)]\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py:873\u001b[0m, in \u001b[0;36mTrackable._add_variable_with_custom_getter\u001b[1;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[0;32m    863\u001b[0m   \u001b[39mif\u001b[39;00m (checkpoint_initializer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    864\u001b[0m       \u001b[39mnot\u001b[39;00m (\u001b[39misinstance\u001b[39m(initializer, CheckpointInitialValueCallable) \u001b[39mand\u001b[39;00m\n\u001b[0;32m    865\u001b[0m            (initializer\u001b[39m.\u001b[39mrestore_uid \u001b[39m>\u001b[39m checkpoint_initializer\u001b[39m.\u001b[39mrestore_uid))):\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    870\u001b[0m     \u001b[39m# then we'll catch that when we call _track_trackable. So this is\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[39m# \"best effort\" to set the initializer with the highest restore UID.\u001b[39;00m\n\u001b[0;32m    872\u001b[0m     initializer \u001b[39m=\u001b[39m checkpoint_initializer\n\u001b[1;32m--> 873\u001b[0m new_variable \u001b[39m=\u001b[39m getter(\n\u001b[0;32m    874\u001b[0m     name\u001b[39m=\u001b[39mname,\n\u001b[0;32m    875\u001b[0m     shape\u001b[39m=\u001b[39mshape,\n\u001b[0;32m    876\u001b[0m     dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m    877\u001b[0m     initializer\u001b[39m=\u001b[39minitializer,\n\u001b[0;32m    878\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs_for_getter)\n\u001b[0;32m    880\u001b[0m \u001b[39m# If we set an initializer and the variable processed it, tracking will not\u001b[39;00m\n\u001b[0;32m    881\u001b[0m \u001b[39m# assign again. It will add this variable to our dependencies, and if there\u001b[39;00m\n\u001b[0;32m    882\u001b[0m \u001b[39m# is a non-trivial restoration queued, it will handle that. This also\u001b[39;00m\n\u001b[0;32m    883\u001b[0m \u001b[39m# handles slot variables.\u001b[39;00m\n\u001b[0;32m    884\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m overwrite \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(new_variable, Trackable):\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer_utils.py:126\u001b[0m, in \u001b[0;36mmake_variable\u001b[1;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner, layout)\u001b[0m\n\u001b[0;32m    119\u001b[0m   use_resource \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    121\u001b[0m \u001b[39mif\u001b[39;00m layout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m   \u001b[39m# In theory, in `use_resource` is True and `collections` is empty\u001b[39;00m\n\u001b[0;32m    123\u001b[0m   \u001b[39m# (that is to say, in TF2), we can use tf.Variable.\u001b[39;00m\n\u001b[0;32m    124\u001b[0m   \u001b[39m# However, this breaks legacy (Estimator) checkpoints because\u001b[39;00m\n\u001b[0;32m    125\u001b[0m   \u001b[39m# it changes variable names. Remove this when V1 is fully deprecated.\u001b[39;00m\n\u001b[1;32m--> 126\u001b[0m   \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mcompat\u001b[39m.\u001b[39;49mv1\u001b[39m.\u001b[39;49mVariable(\n\u001b[0;32m    127\u001b[0m       initial_value\u001b[39m=\u001b[39;49minit_val,\n\u001b[0;32m    128\u001b[0m       name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m    129\u001b[0m       trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[0;32m    130\u001b[0m       caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[0;32m    131\u001b[0m       dtype\u001b[39m=\u001b[39;49mvariable_dtype,\n\u001b[0;32m    132\u001b[0m       validate_shape\u001b[39m=\u001b[39;49mvalidate_shape,\n\u001b[0;32m    133\u001b[0m       constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[0;32m    134\u001b[0m       use_resource\u001b[39m=\u001b[39;49muse_resource,\n\u001b[0;32m    135\u001b[0m       collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[0;32m    136\u001b[0m       synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[0;32m    137\u001b[0m       aggregation\u001b[39m=\u001b[39;49maggregation,\n\u001b[0;32m    138\u001b[0m       shape\u001b[39m=\u001b[39;49mvariable_shape \u001b[39mif\u001b[39;49;00m variable_shape \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m    139\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    140\u001b[0m   \u001b[39mreturn\u001b[39;00m dtensor\u001b[39m.\u001b[39mDVariable(\n\u001b[0;32m    141\u001b[0m       initial_value\u001b[39m=\u001b[39minit_val,\n\u001b[0;32m    142\u001b[0m       name\u001b[39m=\u001b[39mname,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m       aggregation\u001b[39m=\u001b[39maggregation,\n\u001b[0;32m    151\u001b[0m       shape\u001b[39m=\u001b[39mvariable_shape \u001b[39mif\u001b[39;00m variable_shape \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:264\u001b[0m, in \u001b[0;36mVariableMetaclass.__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[39m@traceback_utils\u001b[39m\u001b[39m.\u001b[39mfilter_traceback\n\u001b[0;32m    262\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    263\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m VariableV1:\n\u001b[1;32m--> 264\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_variable_v1_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    265\u001b[0m   \u001b[39melif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m Variable:\n\u001b[0;32m    266\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_variable_v2_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:209\u001b[0m, in \u001b[0;36mVariableMetaclass._variable_v1_call\u001b[1;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[39mif\u001b[39;00m aggregation \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m   aggregation \u001b[39m=\u001b[39m VariableAggregation\u001b[39m.\u001b[39mNONE\n\u001b[1;32m--> 209\u001b[0m \u001b[39mreturn\u001b[39;00m previous_getter(\n\u001b[0;32m    210\u001b[0m     initial_value\u001b[39m=\u001b[39;49minitial_value,\n\u001b[0;32m    211\u001b[0m     trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[0;32m    212\u001b[0m     collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[0;32m    213\u001b[0m     validate_shape\u001b[39m=\u001b[39;49mvalidate_shape,\n\u001b[0;32m    214\u001b[0m     caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[0;32m    215\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m    216\u001b[0m     variable_def\u001b[39m=\u001b[39;49mvariable_def,\n\u001b[0;32m    217\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    218\u001b[0m     expected_shape\u001b[39m=\u001b[39;49mexpected_shape,\n\u001b[0;32m    219\u001b[0m     import_scope\u001b[39m=\u001b[39;49mimport_scope,\n\u001b[0;32m    220\u001b[0m     constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[0;32m    221\u001b[0m     use_resource\u001b[39m=\u001b[39;49muse_resource,\n\u001b[0;32m    222\u001b[0m     synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[0;32m    223\u001b[0m     aggregation\u001b[39m=\u001b[39;49maggregation,\n\u001b[0;32m    224\u001b[0m     shape\u001b[39m=\u001b[39;49mshape)\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:64\u001b[0m, in \u001b[0;36m_make_getter.<locals>.getter\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetter\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m captured_getter(captured_previous, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3604\u001b[0m, in \u001b[0;36m_DefaultDistributionContext.__init__.<locals>.creator\u001b[1;34m(next_creator, **kwargs)\u001b[0m\n\u001b[0;32m   3602\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreator\u001b[39m(next_creator, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   3603\u001b[0m   _require_strategy_scope_strategy(strategy)\n\u001b[1;32m-> 3604\u001b[0m   \u001b[39mreturn\u001b[39;00m next_creator(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:202\u001b[0m, in \u001b[0;36mVariableMetaclass._variable_v1_call.<locals>.<lambda>\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_variable_v1_call\u001b[39m(\u001b[39mcls\u001b[39m,\n\u001b[0;32m    186\u001b[0m                       initial_value\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    187\u001b[0m                       trainable\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    199\u001b[0m                       aggregation\u001b[39m=\u001b[39mVariableAggregation\u001b[39m.\u001b[39mNONE,\n\u001b[0;32m    200\u001b[0m                       shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    201\u001b[0m   \u001b[39m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 202\u001b[0m   previous_getter \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: default_variable_creator(\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    203\u001b[0m   \u001b[39mfor\u001b[39;00m _, getter \u001b[39min\u001b[39;00m ops\u001b[39m.\u001b[39mget_default_graph()\u001b[39m.\u001b[39m_variable_creator_stack:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    204\u001b[0m     previous_getter \u001b[39m=\u001b[39m _make_getter(getter, previous_getter)\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py:2705\u001b[0m, in \u001b[0;36mdefault_variable_creator\u001b[1;34m(next_creator, **kwargs)\u001b[0m\n\u001b[0;32m   2703\u001b[0m \u001b[39mif\u001b[39;00m use_resource:\n\u001b[0;32m   2704\u001b[0m   distribute_strategy \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdistribute_strategy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m-> 2705\u001b[0m   \u001b[39mreturn\u001b[39;00m resource_variable_ops\u001b[39m.\u001b[39;49mResourceVariable(\n\u001b[0;32m   2706\u001b[0m       initial_value\u001b[39m=\u001b[39;49minitial_value,\n\u001b[0;32m   2707\u001b[0m       trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[0;32m   2708\u001b[0m       collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[0;32m   2709\u001b[0m       validate_shape\u001b[39m=\u001b[39;49mvalidate_shape,\n\u001b[0;32m   2710\u001b[0m       caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[0;32m   2711\u001b[0m       name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m   2712\u001b[0m       dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   2713\u001b[0m       constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[0;32m   2714\u001b[0m       variable_def\u001b[39m=\u001b[39;49mvariable_def,\n\u001b[0;32m   2715\u001b[0m       import_scope\u001b[39m=\u001b[39;49mimport_scope,\n\u001b[0;32m   2716\u001b[0m       distribute_strategy\u001b[39m=\u001b[39;49mdistribute_strategy,\n\u001b[0;32m   2717\u001b[0m       synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[0;32m   2718\u001b[0m       aggregation\u001b[39m=\u001b[39;49maggregation,\n\u001b[0;32m   2719\u001b[0m       shape\u001b[39m=\u001b[39;49mshape)\n\u001b[0;32m   2720\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2721\u001b[0m   \u001b[39mreturn\u001b[39;00m variables\u001b[39m.\u001b[39mRefVariable(\n\u001b[0;32m   2722\u001b[0m       initial_value\u001b[39m=\u001b[39minitial_value,\n\u001b[0;32m   2723\u001b[0m       trainable\u001b[39m=\u001b[39mtrainable,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2734\u001b[0m       aggregation\u001b[39m=\u001b[39maggregation,\n\u001b[0;32m   2735\u001b[0m       shape\u001b[39m=\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:268\u001b[0m, in \u001b[0;36mVariableMetaclass.__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    266\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_variable_v2_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    267\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 268\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m(VariableMetaclass, \u001b[39mcls\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1630\u001b[0m, in \u001b[0;36mResourceVariable.__init__\u001b[1;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[0;32m   1627\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_from_proto(variable_def, import_scope\u001b[39m=\u001b[39mimport_scope,\n\u001b[0;32m   1628\u001b[0m                         validate_shape\u001b[39m=\u001b[39mvalidate_shape)\n\u001b[0;32m   1629\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1630\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_from_args(\n\u001b[0;32m   1631\u001b[0m       initial_value\u001b[39m=\u001b[39;49minitial_value,\n\u001b[0;32m   1632\u001b[0m       trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[0;32m   1633\u001b[0m       collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[0;32m   1634\u001b[0m       caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[0;32m   1635\u001b[0m       name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m   1636\u001b[0m       dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1637\u001b[0m       constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[0;32m   1638\u001b[0m       synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[0;32m   1639\u001b[0m       aggregation\u001b[39m=\u001b[39;49maggregation,\n\u001b[0;32m   1640\u001b[0m       shape\u001b[39m=\u001b[39;49mshape,\n\u001b[0;32m   1641\u001b[0m       distribute_strategy\u001b[39m=\u001b[39;49mdistribute_strategy,\n\u001b[0;32m   1642\u001b[0m       validate_shape\u001b[39m=\u001b[39;49mvalidate_shape,\n\u001b[0;32m   1643\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1783\u001b[0m, in \u001b[0;36mResourceVariable._init_from_args\u001b[1;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape, validate_shape)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(\u001b[39m\"\u001b[39m\u001b[39mInitializer\u001b[39m\u001b[39m\"\u001b[39m), device_context_manager(\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1782\u001b[0m   \u001b[39mif\u001b[39;00m init_from_fn:\n\u001b[1;32m-> 1783\u001b[0m     initial_value \u001b[39m=\u001b[39m initial_value()\n\u001b[0;32m   1784\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(initial_value, trackable\u001b[39m.\u001b[39mCheckpointInitialValue):\n\u001b[0;32m   1785\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_initialize_trackable()\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:152\u001b[0m, in \u001b[0;36mZeros.__call__\u001b[1;34m(self, shape, dtype, **kwargs)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[39mif\u001b[39;00m layout:\n\u001b[0;32m    151\u001b[0m   \u001b[39mreturn\u001b[39;00m utils\u001b[39m.\u001b[39mcall_with_layout(tf\u001b[39m.\u001b[39mzeros, layout, shape\u001b[39m=\u001b[39mshape, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m--> 152\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mzeros(shape, dtype)\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1082\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1083\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1084\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:2972\u001b[0m, in \u001b[0;36m_tag_zeros_tensor.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   2971\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m-> 2972\u001b[0m   tensor \u001b[39m=\u001b[39m fun(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   2973\u001b[0m   tensor\u001b[39m.\u001b[39m_is_zeros_tensor \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   2974\u001b[0m   \u001b[39mreturn\u001b[39;00m tensor\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:3033\u001b[0m, in \u001b[0;36mzeros\u001b[1;34m(shape, dtype, name)\u001b[0m\n\u001b[0;32m   3031\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m shape\u001b[39m.\u001b[39m_shape_tuple():\n\u001b[0;32m   3032\u001b[0m     shape \u001b[39m=\u001b[39m reshape(shape, [\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])  \u001b[39m# Ensure it's a vector\u001b[39;00m\n\u001b[1;32m-> 3033\u001b[0m   output \u001b[39m=\u001b[39m fill(shape, constant(zero, dtype\u001b[39m=\u001b[39;49mdtype), name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m   3034\u001b[0m \u001b[39massert\u001b[39;00m output\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype \u001b[39m==\u001b[39m dtype\n\u001b[0;32m   3035\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1082\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1083\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1084\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:246\u001b[0m, in \u001b[0;36mfill\u001b[1;34m(dims, value, name)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mfill\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    208\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[0;32m    209\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfill\u001b[39m(dims, value, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    210\u001b[0m   \u001b[39mr\u001b[39m\u001b[39m\"\"\"Creates a tensor filled with a scalar value.\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \n\u001b[0;32m    212\u001b[0m \u001b[39m  See also `tf.ones`, `tf.zeros`, `tf.one_hot`, `tf.eye`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[39m  @end_compatibility\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 246\u001b[0m   result \u001b[39m=\u001b[39m gen_array_ops\u001b[39m.\u001b[39;49mfill(dims, value, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m    247\u001b[0m   tensor_util\u001b[39m.\u001b[39mmaybe_set_static_shape(result, dims)\n\u001b[0;32m    248\u001b[0m   \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Hi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:3495\u001b[0m, in \u001b[0;36mfill\u001b[1;34m(dims, value, name)\u001b[0m\n\u001b[0;32m   3493\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m   3494\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3495\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m   3496\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mFill\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, dims, value)\n\u001b[0;32m   3497\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m   3498\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def create_model(learning_rate,dropout_rate,activation_function,init,neuron1,neuron2):\n",
    "    model=Sequential()\n",
    "    model.add(Dense(neuron1,input_dim=8,kernel_initializer=init,activation=activation_function))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neuron2,input_dim=8,kernel_initializer=init,activation=activation_function))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    adam= Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss='rmsprop',optimizer=adam,metrics=['accuracy','mse'])\n",
    "    return model\n",
    "\n",
    "#Create Model \n",
    "model =KerasRegressor(build_fn=create_model,verbose=0)\n",
    "\n",
    "#Define Grid Search\n",
    "batch_size=[10,20,40]\n",
    "epochs=[10,50,100]\n",
    "learning_rate=[0.1,0.01,0.001]\n",
    "dropout_rate=[0.0,0.1,0.2]\n",
    "activation_function=['softmax','relu','tanh','linear']\n",
    "init=['uniform','normal','zero']\n",
    "neuron1=[4,8,16]\n",
    "neuron2=[2,4,8]\n",
    "\n",
    "#Make a dictionary of Grid Search parameters\n",
    "params_grid =dict(batch_size=batch_size,epochs=epochs,learning_rate=learning_rate,dropout_rate=dropout_rate,activation_function=activation_function\n",
    "                  , init=init,neuron1=neuron1,neuron2=neuron2)\n",
    "\n",
    "#Build and fit the GridsearchCV\n",
    "grid=GridSearchCV(estimator=model,param_grid=params_grid,verbose=11)\n",
    "grid.fit(X,Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_model(hp):\n",
    "    model=keras.Sequential()\n",
    "    for i in range(hp.Int('num_layers',2,20)):\n",
    "        model.add(layers.Dense(units=hp.Int('units_'+ str(i), min_value=32,max_value=152,step=32),activation=hp.Choice('activation'+str(i),values=['relu','tanh','sigmoid'])))\n",
    "        model.add(Dropout(hp.Choice('dropout'+str(i),values=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9])))\n",
    "        model.add(layers.Dense(1,activation='linear'))\n",
    "        model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate',[1e-2,1e-3,1e-4])),loss='mean_absolute_error',metrics=['mean_absolute_error'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner= RandomSearch(build_model,objective='val_mean_absolute_error',max_trials=5,executions_per_trial=3,directory='project',project_name='Forest Fires',overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(x_train,y_train,epochs=100,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train,y_train,epochs=100,initial_epoch=6,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "978d9105b068cbc356370494e3cb52e52fa7590bb9da26e4b7328c8ae4e62003"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
